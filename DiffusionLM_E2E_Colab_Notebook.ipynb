{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "759f9789",
      "metadata": {
        "id": "759f9789"
      },
      "source": [
        "# 🚀 Diffusion-LM on E2E NLG Dataset with Cosine Noise Schedule (Google Colab)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zx7x4WZ_3ta",
        "outputId": "12df2c11-4371-47f2-ef45-984236908c01"
      },
      "id": "_Zx7x4WZ_3ta",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c918fedc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c918fedc",
        "outputId": "d3cc7aa4-9f2b-4775-e045-820c3526ff71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m128.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [transformers]\n",
            "\u001b[1A\u001b[2K"
          ]
        }
      ],
      "source": [
        "# ✅ Step 1: Restart runtime after running this if you face numpy/mtrand issues\n",
        "!pip install -q --upgrade pip\n",
        "!pip install -q huggingface_hub==0.28.1 transformers==4.41.1 wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q spacy==3.8.2 numpy==2.0.0 datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP4uUfauhyql",
        "outputId": "457741cb-ed0f-4030-b945-c429480c2a9d"
      },
      "id": "kP4uUfauhyql",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m137.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m173.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [spacy]\n",
            "\u001b[1A\u001b[2K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mpi4py\n",
        "!pip install pytorch torchvision torchaudio cudatoolkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__Ja-adGJmiJ",
        "outputId": "6fa18e5b-c79a-4a27-a983-cda66cd27897"
      },
      "id": "__Ja-adGJmiJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpi4py\n",
            "  Downloading mpi4py-4.0.3.tar.gz (466 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-4.0.3-cp311-cp311-linux_x86_64.whl size=4441850 sha256=fb0b64e4e4cf5fdcdf32a5bca2e2ab911620292b7ab50d5f1fdf4deb64685ee3\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/56/17/bf6ba37aa971a191a8b9eaa188bf5ec855b8911c1c56fb1f84\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-4.0.3\n",
            "Collecting pytorch\n",
            "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cudatoolkit (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for cudatoolkit\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCA3DywjMCP7",
        "outputId": "46725745-8a4f-4272-e185-bb122bf0227b"
      },
      "id": "wCA3DywjMCP7",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c06795ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c06795ec",
        "outputId": "7d221528-3598-4616-fe3f-ce7cd8e8de17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All packages imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# ✅ Step 2: Import all required libraries\n",
        "import torch\n",
        "import transformers\n",
        "import datasets\n",
        "import spacy\n",
        "import wandb\n",
        "\n",
        "print(\"✅ All packages imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cea9af77",
      "metadata": {
        "id": "cea9af77"
      },
      "source": [
        "## 📦 Step 3: Clone Diffusion-LM repository and install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "841e71b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "841e71b9",
        "outputId": "771f8cfa-e3b4-46c2-b1f2-b840e1b6207e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Diffusion-LM'...\n",
            "remote: Enumerating objects: 2173, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 2173 (delta 24), reused 11 (delta 11), pack-reused 2108 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2173/2173), 46.02 MiB | 24.15 MiB/s, done.\n",
            "Resolving deltas: 100% (555/555), done.\n",
            "/content/Diffusion-LM\n"
          ]
        }
      ],
      "source": [
        "# Clone the repo\n",
        "!git clone https://github.com/XiangLi1999/Diffusion-LM.git\n",
        "%cd Diffusion-LM\n",
        "\n",
        "# Add repo to Python path (instead of pip install)\n",
        "import sys\n",
        "sys.path.append('/content/Diffusion-LM')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c02831",
      "metadata": {
        "id": "c1c02831"
      },
      "source": [
        "## 📁 Step 4: Download the E2E dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6cf833e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6cf833e",
        "outputId": "1308f390-dece-47dd-ce15-22eb4749d09e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-08 16:07:05--  https://github.com/tuetschek/e2e-dataset/blob/master/trainset.csv\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘data/e2e_data/trainset.csv’\n",
            "\n",
            "data/e2e_data/train     [ <=>                ] 174.12K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-06-08 16:07:06 (1.76 MB/s) - ‘data/e2e_data/trainset.csv’ saved [178299]\n",
            "\n",
            "--2025-06-08 16:07:06--  https://github.com/tuetschek/e2e-dataset/blob/master/devset.csv\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘data/e2e_data/devset.csv’\n",
            "\n",
            "data/e2e_data/devse     [ <=>                ]   1.32M  7.79MB/s    in 0.2s    \n",
            "\n",
            "2025-06-08 16:07:06 (7.79 MB/s) - ‘data/e2e_data/devset.csv’ saved [1380732]\n",
            "\n",
            "--2025-06-08 16:07:06--  https://github.com/tuetschek/e2e-dataset/blob/master/testset.csv\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘data/e2e_data/testset.csv’\n",
            "\n",
            "data/e2e_data/tests     [ <=>                ] 261.70K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-06-08 16:07:07 (2.67 MB/s) - ‘data/e2e_data/testset.csv’ saved [267982]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p data/e2e_data\n",
        "!wget https://github.com/tuetschek/e2e-dataset/blob/master/trainset.csv -O data/e2e_data/trainset.csv\n",
        "!wget https://github.com/tuetschek/e2e-dataset/blob/master/devset.csv -O data/e2e_data/devset.csv\n",
        "!wget https://github.com/tuetschek/e2e-dataset/blob/master/testset.csv -O data/e2e_data/testset.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the Dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "op3hzL6T9Cdh"
      },
      "id": "op3hzL6T9Cdh"
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Diffusion-LM/improved-diffusion/scripts/preprocess_data.py \\\n",
        "    --data_dir /content/Diffusion-LM/data/e2e_data \\\n",
        "    --dataset /content/Diffusion-LM/datasets/e2e_data \\\n",
        "    --tokenizer gpt2 \\\n",
        "    --output_dir /content/Diffusion-LM/datasets/processed_e2e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvD0aYGp-bTF",
        "outputId": "0c9c3206-0233-4e36-a21a-d86f59298116"
      },
      "id": "PvD0aYGp-bTF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98161\n",
            "[\"David noticed he had put on a lot of weight recently. He examined his habits to try and figure out the reason. He realized he'd been eating too much fast food lately. He stopped going to burger places and started a vegetarian diet. After a few weeks, he started to feel much better.\", \"Tom had a very short temper. One day a guest made him very angry. He punched a hole in the wall of his house. Tom's guest became afraid and left quickly. Tom sat on his couch filled with regret about his actions.\"]\n",
            "\n",
            "['The dog jumped up on the bed. I told her to go underneath it like she usually does. She refused to budge from her spot. I tried to make enough room for my legs. I gave up and let her sleep partly on top of me.', 'My family was excited for the fourth of july. We decided to have a Bar BQ. A lot of friends attended the event. We ate burgers. At the end of the night we watched fireworks.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e improved-diffusion/\n",
        "!pip install -e transformers/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulvn90e4IcUo",
        "outputId": "fd7a4273-9b3e-4c40-ac3a-91d67f96e522"
      },
      "id": "Ulvn90e4IcUo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: improved-diffusion/ is not a valid editable requirement. It should either be a path to a local project or a VCS URL (beginning with bzr+http, bzr+https, bzr+ssh, bzr+sftp, bzr+ftp, bzr+lp, bzr+file, git+http, git+https, git+ssh, git+git, git+file, hg+file, hg+http, hg+https, hg+ssh, hg+static-http, svn+ssh, svn+http, svn+https, svn+svn, svn+file).\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: transformers/ is not a valid editable requirement. It should either be a path to a local project or a VCS URL (beginning with bzr+http, bzr+https, bzr+ssh, bzr+sftp, bzr+ftp, bzr+lp, bzr+file, git+http, git+https, git+ssh, git+git, git+file, hg+file, hg+http, hg+https, hg+ssh, hg+static-http, svn+ssh, svn+http, svn+https, svn+svn, svn+file).\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set the Python path"
      ],
      "metadata": {
        "id": "dvLMdDIJErd_"
      },
      "id": "dvLMdDIJErd_"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd //content/Diffusion-LM/improved-diffusion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0pHEB6IFpkv",
        "outputId": "b90fc1cd-e1c5-488f-8872-0945edd02f1f"
      },
      "id": "v0pHEB6IFpkv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Diffusion-LM/improved-diffusion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/Diffusion-LM/improved-diffusion')"
      ],
      "metadata": {
        "id": "UO2vb6ySEqNV"
      },
      "id": "UO2vb6ySEqNV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('/content/Diffusion-LM'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03AO7AN9F_Mx",
        "outputId": "ed276b71-46aa-41b8-c966-6b7332e7ccf0"
      },
      "id": "03AO7AN9F_Mx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['improved-diffusion', 'datasets', 'README.md', 'data', 'LICENSE', 'train_run.py', 'transformers', '.git']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model (Default Noise Schedule)"
      ],
      "metadata": {
        "id": "VoTcSz-EACCw"
      },
      "id": "VoTcSz-EACCw"
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Diffusion-LM/improved-diffusion/scripts/train.py \\\n",
        "    --dataset /content/Diffusion-LM/datasets/e2e_data \\\n",
        "    --data_dir /content/Diffusion-LM/datasets/processed_e2e \\\n",
        "    --output_dir /content/Diffusion-LM/datasets/trained_e2e_baseline \\\n",
        "    --num_train_epochs 5 \\\n",
        "    --learning_rate 5e-5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9FUt4NLAIHI",
        "outputId": "e7260412-3ff0-477c-8f56-abc0d4d8ecfb"
      },
      "id": "I9FUt4NLAIHI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-08 15:37:30.764257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749397051.078002    6357 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749397051.161564    6357 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-08 15:37:31.847991: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "usage: train.py [-h] [--data_dir DATA_DIR]\n",
            "                [--schedule_sampler SCHEDULE_SAMPLER] [--lr LR]\n",
            "                [--weight_decay WEIGHT_DECAY]\n",
            "                [--lr_anneal_steps LR_ANNEAL_STEPS] [--batch_size BATCH_SIZE]\n",
            "                [--microbatch MICROBATCH] [--ema_rate EMA_RATE]\n",
            "                [--log_interval LOG_INTERVAL] [--save_interval SAVE_INTERVAL]\n",
            "                [--resume_checkpoint RESUME_CHECKPOINT] [--use_fp16 USE_FP16]\n",
            "                [--fp16_scale_growth FP16_SCALE_GROWTH] [--seed SEED]\n",
            "                [--gradient_clipping GRADIENT_CLIPPING]\n",
            "                [--eval_interval EVAL_INTERVAL]\n",
            "                [--checkpoint_path CHECKPOINT_PATH] [--image_size IMAGE_SIZE]\n",
            "                [--num_channels NUM_CHANNELS]\n",
            "                [--num_res_blocks NUM_RES_BLOCKS] [--num_heads NUM_HEADS]\n",
            "                [--num_heads_upsample NUM_HEADS_UPSAMPLE]\n",
            "                [--attention_resolutions ATTENTION_RESOLUTIONS]\n",
            "                [--dropout DROPOUT] [--learn_sigma LEARN_SIGMA]\n",
            "                [--sigma_small SIGMA_SMALL] [--class_cond CLASS_COND]\n",
            "                [--diffusion_steps DIFFUSION_STEPS]\n",
            "                [--noise_schedule NOISE_SCHEDULE]\n",
            "                [--timestep_respacing TIMESTEP_RESPACING] [--use_kl USE_KL]\n",
            "                [--predict_xstart PREDICT_XSTART]\n",
            "                [--rescale_timesteps RESCALE_TIMESTEPS]\n",
            "                [--rescale_learned_sigmas RESCALE_LEARNED_SIGMAS]\n",
            "                [--use_checkpoint USE_CHECKPOINT]\n",
            "                [--use_scale_shift_norm USE_SCALE_SHIFT_NORM]\n",
            "                [--model_arch MODEL_ARCH] [--in_channel IN_CHANNEL]\n",
            "                [--out_channel OUT_CHANNEL] [--training_mode TRAINING_MODE]\n",
            "                [--vocab_size VOCAB_SIZE] [--config_name CONFIG_NAME]\n",
            "                [--experiment_mode EXPERIMENT_MODE]\n",
            "                [--logits_mode LOGITS_MODE] [--modality MODALITY]\n",
            "                [--dataset_name DATASET_NAME]\n",
            "                [--dataset_config_name DATASET_CONFIG_NAME] [--config CONFIG]\n",
            "                [--model_name_or_path MODEL_NAME_OR_PATH]\n",
            "                [--experiment EXPERIMENT] [--roc_train ROC_TRAIN]\n",
            "                [--wiki_train WIKI_TRAIN] [--e2e_train E2E_TRAIN]\n",
            "                [--yelp_train YELP_TRAIN] [--commonGen_train COMMONGEN_TRAIN]\n",
            "                [--emb_scale_factor EMB_SCALE_FACTOR]\n",
            "                [--noise_level NOISE_LEVEL] [--cache_mode CACHE_MODE]\n",
            "                [--use_bert_tokenizer USE_BERT_TOKENIZER]\n",
            "                [--padding_mode PADDING_MODE]\n",
            "                [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]\n",
            "train.py: error: ambiguous option: --dataset could match --dataset_name, --dataset_config_name\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/run_train.py --diff_steps 2000 --model_arch transformer --lr 0.0001 --lr_anneal_steps 200000  --seed 102 --noise_schedule sqrt --in_channel 16 --modality e2e-tgt --submit no --padding_mode block --app \"--predict_xstart True --training_mode e2e --vocab_size 821  --e2e_train ../datasets/e2e_data \" --notes xstart_e2e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSf5xencNjOh",
        "outputId": "7d477cd9-6f53-4dda-a1fe-65691055119a"
      },
      "id": "SSf5xencNjOh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.66     |\n",
            "| mse       | 0.238    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0482   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.651    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.223    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0583   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.227    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0495   |\n",
            "| mse_q2    | 0.216    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.224    |\n",
            "| loss      | 0.234    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0577   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.225    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0489   |\n",
            "| mse_q2    | 0.216    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.233    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.06     |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.225    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0511   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0594   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0506   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.216    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0559   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0471   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0584   |\n",
            "| loss_q2   | 0.235    |\n",
            "| loss_q3   | 0.647    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0496   |\n",
            "| mse_q2    | 0.227    |\n",
            "| mse_q3    | 0.638    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "eval on validation set\n",
            "---------------------------\n",
            "| eval_loss    | 0.22     |\n",
            "| eval_loss_q0 | 0.0237   |\n",
            "| eval_loss_q1 | 0.0621   |\n",
            "| eval_loss_q2 | 0.24     |\n",
            "| eval_loss_q3 | 0.686    |\n",
            "| eval_mse     | 0.211    |\n",
            "| eval_mse_q0  | 0.0157   |\n",
            "| eval_mse_q1  | 0.0532   |\n",
            "| eval_mse_q2  | 0.231    |\n",
            "| eval_mse_q3  | 0.677    |\n",
            "---------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.252    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0589   |\n",
            "| loss_q2   | 0.233    |\n",
            "| loss_q3   | 0.662    |\n",
            "| mse       | 0.244    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0502   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.654    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0598   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0176   |\n",
            "| mse_q1    | 0.051    |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0575   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0487   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.248    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0591   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.239    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0503   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.248    |\n",
            "| loss_q0   | 0.0265   |\n",
            "| loss_q1   | 0.0559   |\n",
            "| loss_q2   | 0.237    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.239    |\n",
            "| mse_q0    | 0.0177   |\n",
            "| mse_q1    | 0.0471   |\n",
            "| mse_q2    | 0.228    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0267   |\n",
            "| loss_q1   | 0.057    |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0179   |\n",
            "| mse_q1    | 0.0481   |\n",
            "| mse_q2    | 0.226    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.057    |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.644    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0483   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.635    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0563   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.661    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0475   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.652    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0615   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.0526   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.231    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.057    |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.645    |\n",
            "| mse       | 0.222    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0481   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.636    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.84e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0595   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.0507   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.224    |\n",
            "| loss      | 0.25     |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0589   |\n",
            "| loss_q2   | 0.238    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.241    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0501   |\n",
            "| mse_q2    | 0.23     |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0567   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.0479   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0582   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.227    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0494   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0597   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0509   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0588   |\n",
            "| loss_q2   | 0.235    |\n",
            "| loss_q3   | 0.648    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0501   |\n",
            "| mse_q2    | 0.227    |\n",
            "| mse_q3    | 0.639    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.059    |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0502   |\n",
            "| mse_q2    | 0.212    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.058    |\n",
            "| loss_q2   | 0.237    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0492   |\n",
            "| mse_q2    | 0.228    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.234    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0593   |\n",
            "| loss_q2   | 0.24     |\n",
            "| loss_q3   | 0.639    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0506   |\n",
            "| mse_q2    | 0.231    |\n",
            "| mse_q3    | 0.63     |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0581   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0493   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0588   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.05     |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0559   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.641    |\n",
            "| mse       | 0.235    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0471   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.632    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.223    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0265   |\n",
            "| loss_q1   | 0.058    |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0177   |\n",
            "| mse_q1    | 0.0491   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.18e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.224    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0565   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0477   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.221    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0581   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.671    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0493   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.662    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.224    |\n",
            "| loss      | 0.248    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0588   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.661    |\n",
            "| mse       | 0.24     |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.05     |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.652    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0567   |\n",
            "| loss_q2   | 0.236    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.048    |\n",
            "| mse_q2    | 0.227    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0577   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.66     |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.0489   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.652    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0562   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.641    |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0474   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.633    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.85e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.059    |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.646    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.0502   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.637    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.238    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0584   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.637    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0496   |\n",
            "| mse_q2    | 0.224    |\n",
            "| mse_q3    | 0.628    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.251    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0553   |\n",
            "| loss_q2   | 0.235    |\n",
            "| loss_q3   | 0.664    |\n",
            "| mse       | 0.242    |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.0466   |\n",
            "| mse_q2    | 0.226    |\n",
            "| mse_q3    | 0.655    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0567   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.0479   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.237    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0562   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0474   |\n",
            "| mse_q2    | 0.224    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.234    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0603   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.645    |\n",
            "| mse       | 0.235    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0514   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.636    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.224    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0575   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.661    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0488   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.652    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0586   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.66     |\n",
            "| mse       | 0.235    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0497   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.651    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.238    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0595   |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.227    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0506   |\n",
            "| mse_q2    | 0.212    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.237    |\n",
            "| loss      | 0.249    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0584   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.24     |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0497   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.058    |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0493   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "eval on validation set\n",
            "---------------------------\n",
            "| eval_loss    | 0.233    |\n",
            "| eval_loss_q0 | 0.0256   |\n",
            "| eval_loss_q1 | 0.0647   |\n",
            "| eval_loss_q2 | 0.269    |\n",
            "| eval_loss_q3 | 0.623    |\n",
            "| eval_mse     | 0.224    |\n",
            "| eval_mse_q0  | 0.0168   |\n",
            "| eval_mse_q1  | 0.0557   |\n",
            "| eval_mse_q2  | 0.261    |\n",
            "| eval_mse_q3  | 0.615    |\n",
            "---------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0561   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0474   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0596   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0509   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0562   |\n",
            "| loss_q2   | 0.233    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0474   |\n",
            "| mse_q2    | 0.224    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0577   |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0488   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0563   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0475   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0569   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0481   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.22     |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0567   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.663    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0479   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.654    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0573   |\n",
            "| loss_q2   | 0.236    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0485   |\n",
            "| mse_q2    | 0.227    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.232    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0595   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.224    |\n",
            "| mse_q0    | 0.0176   |\n",
            "| mse_q1    | 0.0508   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.219    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0564   |\n",
            "| loss_q2   | 0.239    |\n",
            "| loss_q3   | 0.659    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0477   |\n",
            "| mse_q2    | 0.23     |\n",
            "| mse_q3    | 0.651    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.86e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0597   |\n",
            "| loss_q2   | 0.237    |\n",
            "| loss_q3   | 0.646    |\n",
            "| mse       | 0.227    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0509   |\n",
            "| mse_q2    | 0.228    |\n",
            "| mse_q3    | 0.638    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.22     |\n",
            "| loss      | 0.249    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0537   |\n",
            "| loss_q2   | 0.233    |\n",
            "| loss_q3   | 0.667    |\n",
            "| mse       | 0.24     |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.045    |\n",
            "| mse_q2    | 0.224    |\n",
            "| mse_q3    | 0.658    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.0255   |\n",
            "| loss_q1   | 0.0561   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.227    |\n",
            "| mse_q0    | 0.0167   |\n",
            "| mse_q1    | 0.0473   |\n",
            "| mse_q2    | 0.216    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.247    |\n",
            "| loss_q0   | 0.0264   |\n",
            "| loss_q1   | 0.0569   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.238    |\n",
            "| mse_q0    | 0.0176   |\n",
            "| mse_q1    | 0.0483   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.19e+07 |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.249    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.057    |\n",
            "| loss_q2   | 0.222    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.24     |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0483   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0569   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0481   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0264   |\n",
            "| loss_q1   | 0.0586   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.235    |\n",
            "| mse_q0    | 0.0176   |\n",
            "| mse_q1    | 0.0497   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.224    |\n",
            "| loss      | 0.25     |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0598   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.646    |\n",
            "| mse       | 0.241    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.051    |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.638    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.058    |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.0493   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0599   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.66     |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0511   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.651    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.06     |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0176   |\n",
            "| mse_q1    | 0.0511   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.248    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.058    |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.239    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0493   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.224    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0571   |\n",
            "| loss_q2   | 0.237    |\n",
            "| loss_q3   | 0.66     |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0483   |\n",
            "| mse_q2    | 0.229    |\n",
            "| mse_q3    | 0.651    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.247    |\n",
            "| loss_q0   | 0.0254   |\n",
            "| loss_q1   | 0.0588   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.238    |\n",
            "| mse_q0    | 0.0167   |\n",
            "| mse_q1    | 0.05     |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0557   |\n",
            "| loss_q2   | 0.241    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0176   |\n",
            "| mse_q1    | 0.0469   |\n",
            "| mse_q2    | 0.232    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.221    |\n",
            "| loss      | 0.231    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0572   |\n",
            "| loss_q2   | 0.219    |\n",
            "| loss_q3   | 0.662    |\n",
            "| mse       | 0.223    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0484   |\n",
            "| mse_q2    | 0.211    |\n",
            "| mse_q3    | 0.653    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0574   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.66     |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0486   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.651    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0583   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0494   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.237    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.056    |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0473   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.87e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0575   |\n",
            "| loss_q2   | 0.219    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.0488   |\n",
            "| mse_q2    | 0.21     |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.232    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0532   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.223    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0445   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.223    |\n",
            "| loss      | 0.235    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0577   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.227    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0489   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.235    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0593   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.645    |\n",
            "| mse       | 0.226    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0504   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.636    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.248    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0545   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.239    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0457   |\n",
            "| mse_q2    | 0.226    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0558   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.047    |\n",
            "| mse_q2    | 0.216    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0585   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0497   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.234    |\n",
            "| loss      | 0.231    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0573   |\n",
            "| loss_q2   | 0.222    |\n",
            "| loss_q3   | 0.633    |\n",
            "| mse       | 0.223    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0485   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.625    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.056    |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.666    |\n",
            "| mse       | 0.235    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0472   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.657    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0564   |\n",
            "| loss_q2   | 0.233    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0168   |\n",
            "| mse_q1    | 0.0476   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.236    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0574   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0486   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "eval on validation set\n",
            "---------------------------\n",
            "| eval_loss    | 0.232    |\n",
            "| eval_loss_q0 | 0.0283   |\n",
            "| eval_loss_q1 | 0.045    |\n",
            "| eval_loss_q2 | 0.237    |\n",
            "| eval_loss_q3 | 0.675    |\n",
            "| eval_mse     | 0.223    |\n",
            "| eval_mse_q0  | 0.02     |\n",
            "| eval_mse_q1  | 0.0366   |\n",
            "| eval_mse_q2  | 0.227    |\n",
            "| eval_mse_q3  | 0.666    |\n",
            "---------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.25     |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0573   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.241    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0486   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.231    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.054    |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.648    |\n",
            "| mse       | 0.222    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0453   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.059    |\n",
            "| loss_q2   | 0.22     |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0502   |\n",
            "| mse_q2    | 0.211    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.234    |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0579   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0491   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.237    |\n",
            "| loss      | 0.253    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0575   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.644    |\n",
            "| mse       | 0.244    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0488   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.635    |\n",
            "| samples   | 1.2e+07  |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.219    |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.054    |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0454   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0576   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0489   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.248    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0564   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.239    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0476   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.25     |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0552   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.241    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0465   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.222    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0587   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.05     |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.88e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.236    |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0584   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0497   |\n",
            "| mse_q2    | 0.216    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.224    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.058    |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.661    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0492   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.653    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0594   |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0505   |\n",
            "| mse_q2    | 0.212    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.235    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0264   |\n",
            "| loss_q1   | 0.057    |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0176   |\n",
            "| mse_q1    | 0.0483   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.249    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0544   |\n",
            "| loss_q2   | 0.237    |\n",
            "| loss_q3   | 0.659    |\n",
            "| mse       | 0.24     |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0458   |\n",
            "| mse_q2    | 0.228    |\n",
            "| mse_q3    | 0.65     |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0587   |\n",
            "| loss_q2   | 0.238    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0499   |\n",
            "| mse_q2    | 0.229    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.221    |\n",
            "| loss      | 0.249    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0554   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.667    |\n",
            "| mse       | 0.24     |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.0467   |\n",
            "| mse_q2    | 0.216    |\n",
            "| mse_q3    | 0.658    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.235    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.058    |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.644    |\n",
            "| mse       | 0.227    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0493   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.635    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.25     |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0579   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.241    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0493   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0264   |\n",
            "| loss_q1   | 0.0574   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.661    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0177   |\n",
            "| mse_q1    | 0.0486   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.652    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0264   |\n",
            "| loss_q1   | 0.058    |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0176   |\n",
            "| mse_q1    | 0.0492   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0567   |\n",
            "| loss_q2   | 0.233    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.235    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.048    |\n",
            "| mse_q2    | 0.224    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0583   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0495   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.232    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.058    |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.223    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0492   |\n",
            "| mse_q2    | 0.216    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.236    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0588   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.05     |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0572   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.641    |\n",
            "| mse       | 0.227    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0484   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.633    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0574   |\n",
            "| loss_q2   | 0.217    |\n",
            "| loss_q3   | 0.644    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0487   |\n",
            "| mse_q2    | 0.208    |\n",
            "| mse_q3    | 0.635    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0591   |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.662    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0503   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.653    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.056    |\n",
            "| loss_q2   | 0.219    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0168   |\n",
            "| mse_q1    | 0.0472   |\n",
            "| mse_q2    | 0.21     |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.89e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0561   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.663    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0474   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.654    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0593   |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0505   |\n",
            "| mse_q2    | 0.212    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0553   |\n",
            "| loss_q2   | 0.217    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0466   |\n",
            "| mse_q2    | 0.208    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0578   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.049    |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.235    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0574   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.226    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0487   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0572   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.646    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0176   |\n",
            "| mse_q1    | 0.0484   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.637    |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0551   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.659    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0464   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.65     |\n",
            "| samples   | 1.21e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0561   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.235    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0473   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.222    |\n",
            "| loss      | 0.247    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.056    |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.663    |\n",
            "| mse       | 0.238    |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.0474   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.654    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.224    |\n",
            "| loss      | 0.249    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0574   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.241    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0487   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.234    |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.06     |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0513   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "eval on validation set\n",
            "---------------------------\n",
            "| eval_loss    | 0.27     |\n",
            "| eval_loss_q0 | 0.023    |\n",
            "| eval_loss_q1 | 0.0609   |\n",
            "| eval_loss_q2 | 0.265    |\n",
            "| eval_loss_q3 | 0.68     |\n",
            "| eval_mse     | 0.261    |\n",
            "| eval_mse_q0  | 0.0149   |\n",
            "| eval_mse_q1  | 0.0526   |\n",
            "| eval_mse_q2  | 0.256    |\n",
            "| eval_mse_q3  | 0.672    |\n",
            "---------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0564   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.648    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0477   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.639    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.0265   |\n",
            "| loss_q1   | 0.0562   |\n",
            "| loss_q2   | 0.233    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0177   |\n",
            "| mse_q1    | 0.0475   |\n",
            "| mse_q2    | 0.224    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0574   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.66     |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0486   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.651    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.223    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0562   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.648    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0474   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.639    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0553   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.665    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0466   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.656    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.057    |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0482   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0585   |\n",
            "| loss_q2   | 0.236    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0498   |\n",
            "| mse_q2    | 0.227    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.0253   |\n",
            "| loss_q1   | 0.0571   |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.664    |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0167   |\n",
            "| mse_q1    | 0.0484   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.655    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.235    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0569   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.647    |\n",
            "| mse       | 0.226    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0482   |\n",
            "| mse_q2    | 0.216    |\n",
            "| mse_q3    | 0.638    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0553   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0466   |\n",
            "| mse_q2    | 0.226    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.9e+05  |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0556   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0468   |\n",
            "| mse_q2    | 0.226    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.234    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0568   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.225    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0481   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0573   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0485   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0579   |\n",
            "| loss_q2   | 0.236    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0492   |\n",
            "| mse_q2    | 0.227    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.235    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0586   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.226    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0498   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.219    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0549   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.647    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0462   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.638    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0549   |\n",
            "| loss_q2   | 0.24     |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.227    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0462   |\n",
            "| mse_q2    | 0.231    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.252    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0581   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.244    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0493   |\n",
            "| mse_q2    | 0.216    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0565   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0478   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0589   |\n",
            "| loss_q2   | 0.218    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0501   |\n",
            "| mse_q2    | 0.209    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0572   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.235    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0484   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.229    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0551   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.636    |\n",
            "| mse       | 0.22     |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0464   |\n",
            "| mse_q2    | 0.216    |\n",
            "| mse_q3    | 0.628    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0583   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0495   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.247    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0585   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.659    |\n",
            "| mse       | 0.238    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0497   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.651    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0568   |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0481   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0551   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0463   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.057    |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.0483   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0544   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0457   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.22e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.234    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0255   |\n",
            "| loss_q1   | 0.0556   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0167   |\n",
            "| mse_q1    | 0.0469   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.91e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0584   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0497   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0602   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.66     |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0514   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.651    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.249    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0577   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.661    |\n",
            "| mse       | 0.241    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0489   |\n",
            "| mse_q2    | 0.226    |\n",
            "| mse_q3    | 0.652    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.252    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0582   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.243    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0495   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.224    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0573   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0486   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0557   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0469   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0567   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0479   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0575   |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.645    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0488   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.637    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.25     |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0567   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.241    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0479   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.223    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0555   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0468   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0538   |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.227    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0451   |\n",
            "| mse_q2    | 0.213    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "eval on validation set\n",
            "---------------------------\n",
            "| eval_loss    | 0.286    |\n",
            "| eval_loss_q0 | 0.0246   |\n",
            "| eval_loss_q1 | 0.0434   |\n",
            "| eval_loss_q2 | 0.23     |\n",
            "| eval_loss_q3 | 0.662    |\n",
            "| eval_mse     | 0.277    |\n",
            "| eval_mse_q0  | 0.0161   |\n",
            "| eval_mse_q1  | 0.0354   |\n",
            "| eval_mse_q2  | 0.221    |\n",
            "| eval_mse_q3  | 0.653    |\n",
            "---------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0579   |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0491   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0573   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.646    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0485   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.638    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0561   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.648    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0473   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0563   |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0475   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0565   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0477   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.219    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0539   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.661    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0452   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.652    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.0255   |\n",
            "| loss_q1   | 0.0567   |\n",
            "| loss_q2   | 0.238    |\n",
            "| loss_q3   | 0.659    |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0168   |\n",
            "| mse_q1    | 0.048    |\n",
            "| mse_q2    | 0.229    |\n",
            "| mse_q3    | 0.65     |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.23     |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0571   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.645    |\n",
            "| mse       | 0.222    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0483   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.637    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0579   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0491   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.221    |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0559   |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0472   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.92e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.223    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0561   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0474   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0264   |\n",
            "| loss_q1   | 0.0554   |\n",
            "| loss_q2   | 0.236    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0177   |\n",
            "| mse_q1    | 0.0467   |\n",
            "| mse_q2    | 0.227    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.249    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0577   |\n",
            "| loss_q2   | 0.218    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.241    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0489   |\n",
            "| mse_q2    | 0.21     |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.234    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0582   |\n",
            "| loss_q2   | 0.222    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.0494   |\n",
            "| mse_q2    | 0.213    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.233    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0569   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.224    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0482   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0575   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.227    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0488   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0553   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0176   |\n",
            "| mse_q1    | 0.0465   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.056    |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0473   |\n",
            "| mse_q2    | 0.212    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0567   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.646    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0479   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.637    |\n",
            "| samples   | 1.23e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0575   |\n",
            "| loss_q2   | 0.235    |\n",
            "| loss_q3   | 0.659    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0489   |\n",
            "| mse_q2    | 0.227    |\n",
            "| mse_q3    | 0.65     |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0568   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.661    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0481   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.652    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.223    |\n",
            "| loss      | 0.232    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0552   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.644    |\n",
            "| mse       | 0.223    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0465   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.635    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.221    |\n",
            "| loss      | 0.247    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0569   |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.662    |\n",
            "| mse       | 0.238    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0481   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.653    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0571   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0484   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0583   |\n",
            "| loss_q2   | 0.24     |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0496   |\n",
            "| mse_q2    | 0.231    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0572   |\n",
            "| loss_q2   | 0.218    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0484   |\n",
            "| mse_q2    | 0.209    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.235    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0574   |\n",
            "| loss_q2   | 0.233    |\n",
            "| loss_q3   | 0.642    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0487   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.633    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0255   |\n",
            "| loss_q1   | 0.0577   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.659    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0167   |\n",
            "| mse_q1    | 0.049    |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.65     |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0563   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0475   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.93e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.219    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0563   |\n",
            "| loss_q2   | 0.233    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0475   |\n",
            "| mse_q2    | 0.224    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.249    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0598   |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.24     |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.051    |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.255    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0564   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.246    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0477   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0586   |\n",
            "| loss_q2   | 0.235    |\n",
            "| loss_q3   | 0.66     |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0498   |\n",
            "| mse_q2    | 0.226    |\n",
            "| mse_q3    | 0.651    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0569   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0481   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.241    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0584   |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.641    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0497   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.632    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0566   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0479   |\n",
            "| mse_q2    | 0.226    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0566   |\n",
            "| loss_q2   | 0.235    |\n",
            "| loss_q3   | 0.665    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0479   |\n",
            "| mse_q2    | 0.226    |\n",
            "| mse_q3    | 0.656    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0555   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.647    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0467   |\n",
            "| mse_q2    | 0.216    |\n",
            "| mse_q3    | 0.638    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0586   |\n",
            "| loss_q2   | 0.222    |\n",
            "| loss_q3   | 0.663    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0498   |\n",
            "| mse_q2    | 0.213    |\n",
            "| mse_q3    | 0.654    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0569   |\n",
            "| loss_q2   | 0.222    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0176   |\n",
            "| mse_q1    | 0.0482   |\n",
            "| mse_q2    | 0.213    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "eval on validation set\n",
            "---------------------------\n",
            "| eval_loss    | 0.214    |\n",
            "| eval_loss_q0 | 0.03     |\n",
            "| eval_loss_q1 | 0.055    |\n",
            "| eval_loss_q2 | 0.239    |\n",
            "| eval_loss_q3 | 0.616    |\n",
            "| eval_mse     | 0.205    |\n",
            "| eval_mse_q0  | 0.0209   |\n",
            "| eval_mse_q1  | 0.0461   |\n",
            "| eval_mse_q2  | 0.23     |\n",
            "| eval_mse_q3  | 0.607    |\n",
            "---------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.221    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0549   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0461   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0583   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.648    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0168   |\n",
            "| mse_q1    | 0.0496   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0563   |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0476   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0573   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.227    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0486   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0547   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0459   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0584   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0496   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.234    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0544   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0457   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.235    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0556   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.659    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0469   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.65     |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.219    |\n",
            "| loss      | 0.235    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.055    |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.226    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0463   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.224    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0546   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.665    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.046    |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.656    |\n",
            "| samples   | 1.24e+07 |\n",
            "| step      | 1.94e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.235    |\n",
            "| loss      | 0.249    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.058    |\n",
            "| loss_q2   | 0.222    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.24     |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0493   |\n",
            "| mse_q2    | 0.213    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0555   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.646    |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0467   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.637    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.0255   |\n",
            "| loss_q1   | 0.0578   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0167   |\n",
            "| mse_q1    | 0.049    |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0568   |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0481   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0545   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0457   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0584   |\n",
            "| loss_q2   | 0.218    |\n",
            "| loss_q3   | 0.661    |\n",
            "| mse       | 0.235    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0497   |\n",
            "| mse_q2    | 0.209    |\n",
            "| mse_q3    | 0.653    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.248    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0586   |\n",
            "| loss_q2   | 0.219    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.239    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0499   |\n",
            "| mse_q2    | 0.21     |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0581   |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.643    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0494   |\n",
            "| mse_q2    | 0.212    |\n",
            "| mse_q3    | 0.634    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.222    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0549   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0461   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.056    |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0473   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0562   |\n",
            "| loss_q2   | 0.216    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0474   |\n",
            "| mse_q2    | 0.207    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0255   |\n",
            "| loss_q1   | 0.0562   |\n",
            "| loss_q2   | 0.222    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0168   |\n",
            "| mse_q1    | 0.0474   |\n",
            "| mse_q2    | 0.213    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.25     |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0582   |\n",
            "| loss_q2   | 0.239    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.241    |\n",
            "| mse_q0    | 0.0176   |\n",
            "| mse_q1    | 0.0495   |\n",
            "| mse_q2    | 0.231    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0558   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.648    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0471   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.057    |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.648    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0483   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.639    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.232    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0588   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.224    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0501   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.234    |\n",
            "| loss_q0   | 0.0255   |\n",
            "| loss_q1   | 0.0555   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.225    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0468   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0573   |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0486   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0569   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0481   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.95e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0255   |\n",
            "| loss_q1   | 0.0546   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.659    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0168   |\n",
            "| mse_q1    | 0.046    |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.65     |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0551   |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0464   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0568   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.048    |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.238    |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0579   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.238    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0492   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0598   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0511   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0568   |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.647    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0481   |\n",
            "| mse_q2    | 0.212    |\n",
            "| mse_q3    | 0.638    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.234    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0537   |\n",
            "| loss_q2   | 0.22     |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0451   |\n",
            "| mse_q2    | 0.211    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0563   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0476   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0572   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0485   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.221    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0251   |\n",
            "| loss_q1   | 0.0565   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.662    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0165   |\n",
            "| mse_q1    | 0.0478   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.654    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.249    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0561   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.24     |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0473   |\n",
            "| mse_q2    | 0.224    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "eval on validation set\n",
            "---------------------------\n",
            "| eval_loss    | 0.26     |\n",
            "| eval_loss_q0 | 0.023    |\n",
            "| eval_loss_q1 | 0.0529   |\n",
            "| eval_loss_q2 | 0.272    |\n",
            "| eval_loss_q3 | 0.666    |\n",
            "| eval_mse     | 0.252    |\n",
            "| eval_mse_q0  | 0.0146   |\n",
            "| eval_mse_q1  | 0.0439   |\n",
            "| eval_mse_q2  | 0.263    |\n",
            "| eval_mse_q3  | 0.658    |\n",
            "---------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.23     |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0547   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.221    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0461   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.25e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0564   |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.66     |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0477   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.651    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.237    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0572   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0484   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.235    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.059    |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.226    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0502   |\n",
            "| mse_q2    | 0.212    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.237    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0573   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.659    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0486   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.65     |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.239    |\n",
            "| loss      | 0.25     |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0562   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.241    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0476   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.055    |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0463   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0553   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.645    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0466   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.637    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.251    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0566   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.243    |\n",
            "| mse_q0    | 0.0176   |\n",
            "| mse_q1    | 0.0479   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0546   |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.046    |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.96e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0552   |\n",
            "| loss_q2   | 0.222    |\n",
            "| loss_q3   | 0.644    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0465   |\n",
            "| mse_q2    | 0.213    |\n",
            "| mse_q3    | 0.635    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.235    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0545   |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.643    |\n",
            "| mse       | 0.226    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0459   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.634    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.236    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0562   |\n",
            "| loss_q2   | 0.236    |\n",
            "| loss_q3   | 0.64     |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0474   |\n",
            "| mse_q2    | 0.227    |\n",
            "| mse_q3    | 0.631    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.248    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0576   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.659    |\n",
            "| mse       | 0.24     |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0488   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.65     |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.235    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0572   |\n",
            "| loss_q2   | 0.22     |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.226    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0484   |\n",
            "| mse_q2    | 0.211    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.235    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0561   |\n",
            "| loss_q2   | 0.222    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0473   |\n",
            "| mse_q2    | 0.213    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0263   |\n",
            "| loss_q1   | 0.0562   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.66     |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0176   |\n",
            "| mse_q1    | 0.0474   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.651    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.221    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0538   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.66     |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0451   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.651    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0595   |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.644    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0507   |\n",
            "| mse_q2    | 0.212    |\n",
            "| mse_q3    | 0.636    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.056    |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0473   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0255   |\n",
            "| loss_q1   | 0.0566   |\n",
            "| loss_q2   | 0.217    |\n",
            "| loss_q3   | 0.662    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0478   |\n",
            "| mse_q2    | 0.208    |\n",
            "| mse_q3    | 0.653    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0599   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0511   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.247    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0559   |\n",
            "| loss_q2   | 0.235    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.238    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0472   |\n",
            "| mse_q2    | 0.226    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0549   |\n",
            "| loss_q2   | 0.22     |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0462   |\n",
            "| mse_q2    | 0.211    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0567   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.644    |\n",
            "| mse       | 0.233    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0481   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.636    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0563   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0476   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.65     |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0583   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0495   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0576   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0489   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.235    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0544   |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.227    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0456   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.97e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.234    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0581   |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.226    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0494   |\n",
            "| mse_q2    | 0.213    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0562   |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.659    |\n",
            "| mse       | 0.235    |\n",
            "| mse_q0    | 0.0168   |\n",
            "| mse_q1    | 0.0474   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.65     |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0566   |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.659    |\n",
            "| mse       | 0.235    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0479   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.65     |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.224    |\n",
            "| loss      | 0.233    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0554   |\n",
            "| loss_q2   | 0.218    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.224    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0467   |\n",
            "| mse_q2    | 0.209    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.26e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.237    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0562   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.648    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0475   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.639    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.057    |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0168   |\n",
            "| mse_q1    | 0.0482   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0583   |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0495   |\n",
            "| mse_q2    | 0.213    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.0255   |\n",
            "| loss_q1   | 0.0557   |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.238    |\n",
            "| mse_q0    | 0.0168   |\n",
            "| mse_q1    | 0.0469   |\n",
            "| mse_q2    | 0.212    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0556   |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0469   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0255   |\n",
            "| loss_q1   | 0.0552   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0465   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0585   |\n",
            "| loss_q2   | 0.223    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0497   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "eval on validation set\n",
            "---------------------------\n",
            "| eval_loss    | 0.241    |\n",
            "| eval_loss_q0 | 0.025    |\n",
            "| eval_loss_q1 | 0.085    |\n",
            "| eval_loss_q2 | 0.238    |\n",
            "| eval_loss_q3 | 0.61     |\n",
            "| eval_mse     | 0.232    |\n",
            "| eval_mse_q0  | 0.0161   |\n",
            "| eval_mse_q1  | 0.0757   |\n",
            "| eval_mse_q2  | 0.23     |\n",
            "| eval_mse_q3  | 0.602    |\n",
            "---------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0587   |\n",
            "| loss_q2   | 0.235    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.05     |\n",
            "| mse_q2    | 0.226    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0555   |\n",
            "| loss_q2   | 0.214    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0468   |\n",
            "| mse_q2    | 0.206    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.236    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0576   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0488   |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.224    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0548   |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.667    |\n",
            "| mse       | 0.227    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0461   |\n",
            "| mse_q2    | 0.213    |\n",
            "| mse_q3    | 0.658    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.236    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0562   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0475   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.642    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.234    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.054    |\n",
            "| loss_q2   | 0.238    |\n",
            "| loss_q3   | 0.651    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0453   |\n",
            "| mse_q2    | 0.229    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.232    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0565   |\n",
            "| loss_q2   | 0.222    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.223    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0478   |\n",
            "| mse_q2    | 0.214    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.056    |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0473   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.226    |\n",
            "| loss      | 0.235    |\n",
            "| loss_q0   | 0.0261   |\n",
            "| loss_q1   | 0.0551   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.226    |\n",
            "| mse_q0    | 0.0174   |\n",
            "| mse_q1    | 0.0464   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.247    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0576   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.239    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.049    |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.98e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.237    |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.0255   |\n",
            "| loss_q1   | 0.0582   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.238    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0495   |\n",
            "| mse_q2    | 0.216    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.247    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0577   |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.238    |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.049    |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0569   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.665    |\n",
            "| mse       | 0.235    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0482   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.656    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0559   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.656    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0472   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.223    |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0572   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.645    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0485   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.636    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0562   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.652    |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0475   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.643    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.228    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0575   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.648    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0488   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.639    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0255   |\n",
            "| loss_q1   | 0.0545   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0168   |\n",
            "| mse_q1    | 0.0458   |\n",
            "| mse_q2    | 0.216    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.249    |\n",
            "| loss_q0   | 0.0262   |\n",
            "| loss_q1   | 0.0565   |\n",
            "| loss_q2   | 0.221    |\n",
            "| loss_q3   | 0.655    |\n",
            "| mse       | 0.24     |\n",
            "| mse_q0    | 0.0175   |\n",
            "| mse_q1    | 0.0478   |\n",
            "| mse_q2    | 0.213    |\n",
            "| mse_q3    | 0.647    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.239    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0553   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.23     |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0466   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.235    |\n",
            "| loss      | 0.242    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0584   |\n",
            "| loss_q2   | 0.231    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0497   |\n",
            "| mse_q2    | 0.222    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0255   |\n",
            "| loss_q1   | 0.0537   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0168   |\n",
            "| mse_q1    | 0.045    |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.646    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0556   |\n",
            "| loss_q2   | 0.232    |\n",
            "| loss_q3   | 0.645    |\n",
            "| mse       | 0.236    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0469   |\n",
            "| mse_q2    | 0.223    |\n",
            "| mse_q3    | 0.637    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.249    |\n",
            "| loss_q0   | 0.0257   |\n",
            "| loss_q1   | 0.0574   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.241    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0488   |\n",
            "| mse_q2    | 0.217    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.27e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.232    |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.057    |\n",
            "| loss_q2   | 0.235    |\n",
            "| loss_q3   | 0.648    |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0169   |\n",
            "| mse_q1    | 0.0482   |\n",
            "| mse_q2    | 0.226    |\n",
            "| mse_q3    | 0.639    |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.233    |\n",
            "| loss      | 0.245    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0556   |\n",
            "| loss_q2   | 0.233    |\n",
            "| loss_q3   | 0.648    |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0469   |\n",
            "| mse_q2    | 0.224    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.24     |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0577   |\n",
            "| loss_q2   | 0.23     |\n",
            "| loss_q3   | 0.66     |\n",
            "| mse       | 0.231    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.049    |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.651    |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.246    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0547   |\n",
            "| loss_q2   | 0.228    |\n",
            "| loss_q3   | 0.649    |\n",
            "| mse       | 0.237    |\n",
            "| mse_q0    | 0.0173   |\n",
            "| mse_q1    | 0.0461   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.64     |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.227    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0538   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.235    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0451   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 1.99e+05 |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.244    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0565   |\n",
            "| loss_q2   | 0.234    |\n",
            "| loss_q3   | 0.647    |\n",
            "| mse       | 0.235    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0477   |\n",
            "| mse_q2    | 0.225    |\n",
            "| mse_q3    | 0.638    |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 2e+05    |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.23     |\n",
            "| loss      | 0.238    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0572   |\n",
            "| loss_q2   | 0.227    |\n",
            "| loss_q3   | 0.657    |\n",
            "| mse       | 0.229    |\n",
            "| mse_q0    | 0.0171   |\n",
            "| mse_q1    | 0.0484   |\n",
            "| mse_q2    | 0.219    |\n",
            "| mse_q3    | 0.648    |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 2e+05    |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.234    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0575   |\n",
            "| loss_q2   | 0.22     |\n",
            "| loss_q3   | 0.65     |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0488   |\n",
            "| mse_q2    | 0.211    |\n",
            "| mse_q3    | 0.641    |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 2e+05    |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.237    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0559   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.646    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0471   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.638    |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 2e+05    |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.223    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.026    |\n",
            "| loss_q1   | 0.0552   |\n",
            "| loss_q2   | 0.226    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0465   |\n",
            "| mse_q2    | 0.218    |\n",
            "| mse_q3    | 0.649    |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 2e+05    |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.231    |\n",
            "| loss      | 0.235    |\n",
            "| loss_q0   | 0.0256   |\n",
            "| loss_q1   | 0.0565   |\n",
            "| loss_q2   | 0.225    |\n",
            "| loss_q3   | 0.654    |\n",
            "| mse       | 0.226    |\n",
            "| mse_q0    | 0.017    |\n",
            "| mse_q1    | 0.0478   |\n",
            "| mse_q2    | 0.216    |\n",
            "| mse_q3    | 0.645    |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 2e+05    |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.236    |\n",
            "| loss      | 0.237    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0554   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.228    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0467   |\n",
            "| mse_q2    | 0.22     |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 2e+05    |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.224    |\n",
            "| loss      | 0.241    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0563   |\n",
            "| loss_q2   | 0.233    |\n",
            "| loss_q3   | 0.653    |\n",
            "| mse       | 0.232    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0476   |\n",
            "| mse_q2    | 0.224    |\n",
            "| mse_q3    | 0.644    |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 2e+05    |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.229    |\n",
            "| loss      | 0.231    |\n",
            "| loss_q0   | 0.0258   |\n",
            "| loss_q1   | 0.0559   |\n",
            "| loss_q2   | 0.224    |\n",
            "| loss_q3   | 0.661    |\n",
            "| mse       | 0.223    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.0471   |\n",
            "| mse_q2    | 0.215    |\n",
            "| mse_q3    | 0.652    |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 2e+05    |\n",
            "------------------------\n",
            "------------------------\n",
            "| grad_norm | 0.225    |\n",
            "| loss      | 0.243    |\n",
            "| loss_q0   | 0.0259   |\n",
            "| loss_q1   | 0.0557   |\n",
            "| loss_q2   | 0.229    |\n",
            "| loss_q3   | 0.658    |\n",
            "| mse       | 0.234    |\n",
            "| mse_q0    | 0.0172   |\n",
            "| mse_q1    | 0.047    |\n",
            "| mse_q2    | 0.221    |\n",
            "| mse_q3    | 0.65     |\n",
            "| samples   | 1.28e+07 |\n",
            "| step      | 2e+05    |\n",
            "------------------------\n",
            "saving model 0...\n",
            "writing to diffusion_models/diff_e2e-tgt_block_rand16_transformer_lr0.0001_0.0_2000_sqrt_Lsimple_h128_s2_d0.1_sd102_xstart_e2e/model200000.pt\n",
            "writing to diffusion_models/diff_e2e-tgt_block_rand16_transformer_lr0.0001_0.0_2000_sqrt_Lsimple_h128_s2_d0.1_sd102_xstart_e2e/model200000.pt\n",
            "saving model 0.9999...\n",
            "writing to diffusion_models/diff_e2e-tgt_block_rand16_transformer_lr0.0001_0.0_2000_sqrt_Lsimple_h128_s2_d0.1_sd102_xstart_e2e/ema_0.9999_200000.pt\n",
            "writing to diffusion_models/diff_e2e-tgt_block_rand16_transformer_lr0.0001_0.0_2000_sqrt_Lsimple_h128_s2_d0.1_sd102_xstart_e2e/ema_0.9999_200000.pt\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/Diffusion-LM/improved-diffusion/wandb/offline-run-20250608_161431-q5zoaih8\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20250608_161431-q5zoaih8/logs\u001b[0m\n",
            "[rank0]:[W609 02:02:34.602016747 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ptx3NJo6lvvR"
      },
      "id": "ptx3NJo6lvvR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#backup !python /content/Diffusion-LM/improved-diffusion/scripts/run_train.py \\\n",
        "      --diff_steps 2000 \\\n",
        "      --model_arch transformer \\\n",
        "      --lr 0.0001 \\\n",
        "      --lr_anneal_steps 200000  \\\n",
        "      --seed 102 \\\n",
        "      --noise_schedule sqrt \\\n",
        "      --in_channel 16 \\\n",
        "      --modality e2e-tgt \\\n",
        "      --submit no \\\n",
        "      --padding_mode block \\\n",
        "      --notes xstart_e2e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dv5W45neHcj7",
        "outputId": "42d81394-d503-4e24-e2d2-f5bfa4b489f2"
      },
      "id": "Dv5W45neHcj7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " OPENAI_LOGDIR=diffusion_models/diff_e2e-tgt_block_rand16_transformer_lr0.0001_0.0_2000_sqrt_Lsimple_h128_s2_d0.1_sd102_xstart_e2e  TOKENIZERS_PARALLELISM=false python scripts/train.py   --checkpoint_path diffusion_models/diff_e2e-tgt_block_rand16_transformer_lr0.0001_0.0_2000_sqrt_Lsimple_h128_s2_d0.1_sd102_xstart_e2e --model_arch transformer --modality e2e-tgt --save_interval 50000 --lr 0.0001 --batch_size 64  --diffusion_steps 2000 --noise_schedule sqrt  --use_kl False --learn_sigma False  --image_size 8 --num_channels 128 --seed 102 --dropout 0.1 --in_channel 16 --out_channel 16 --padding_mode block --experiment random  --lr_anneal_steps 200000 --weight_decay 0.0 --num_res_blocks 2  \n",
            "python3: can't open file '/content/Diffusion-LM/scripts/train.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!mkdir -p generation_outputs"
      ],
      "metadata": {
        "id": "nb55HFt2oDV2"
      },
      "id": "nb55HFt2oDV2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# The log content should be available in the notebook's output cells\n",
        "# We will simulate reading from a log string for demonstration purposes.\n",
        "# In a real scenario, you might read this from a saved 'decode_log.txt' file\n",
        "# or directly capture the output of the training cell if it's long.\n",
        "\n",
        "# For demonstration, paste a large chunk of your output here if running locally\n",
        "# For Colab, you can directly access the output of the cell where run_train.py was executed.\n",
        "# If the output is too large, it might be truncated.\n",
        "# You might need to redirect the output to a file and read from it if the notebook output is truncated.\n",
        "# Example: !python scripts/run_train.py ... > full_decode_log.txt 2>&1\n",
        "# Then: with open('full_decode_log.txt', 'r') as f:\n",
        "#           log_content = f.read()\n",
        "\n",
        "# Let's assume you've copied the relevant truncated output into a variable,\n",
        "# or read it from a file (replace '...' with actual log content or load from file)\n",
        "# If running in Colab, you might capture the output of the training cell like this:\n",
        "# from IPython.display import HTML, display\n",
        "# js_code = \"\"\"\n",
        "#     const output = google.colab.kernel.display.get   (element).parentNode.parentNode.querySelector('.output_subarea').textContent;\n",
        "#     google.colab.kernel.invokeFunction('notebook_output_callback', [output]);\n",
        "# \"\"\"\n",
        "# display(HTML(f\"<script>{js_code}</script>\"))\n",
        "# Then define a Python function to receive it:\n",
        "# from google.colab import output as colab_output\n",
        "# class CollectOutput:\n",
        "#     def __init__(self):\n",
        "#         self.output_str = \"\"\n",
        "#     def collect_output(self, output_str):\n",
        "#         self.output_str = output_str\n",
        "# collector = CollectOutput()\n",
        "# colab_output.register_callback('notebook_output_callback', collector.collect_output)\n",
        "# # After executing the training cell, run the js_code then:\n",
        "# # log_content = collector.output_str\n",
        "\n",
        "\n",
        "# For now, I'll use a placeholder for the log content based on what you provided in the previous turn.\n",
        "# In your actual notebook, ensure this 'log_content' variable holds the full log.\n",
        "log_content = \"\"\"\n",
        "------------------------\n",
        "| grad_norm | 0.23     |\n",
        "| loss      | 0.252    |\n",
        "| loss_q0   | 0.0257   |\n",
        "| loss_q1   | 0.0589   |\n",
        "| loss_q2   | 0.233    |\n",
        "| loss_q3   | 0.662    |\n",
        "| mse       | 0.244    |\n",
        "| mse_q0    | 0.017    |\n",
        "| mse_q1    | 0.0502   |\n",
        "| mse_q2    | 0.225    |\n",
        "| mse_q3    | 0.654    |\n",
        "| samples   | 1.18e+07 |\n",
        "| step      | 1.84e+05 |\n",
        "------------------------\n",
        "eval on validation set\n",
        "---------------------------\n",
        "| eval_loss    | 0.22     |\n",
        "| eval_loss_q0 | 0.0237   |\n",
        "| eval_loss_q1 | 0.0621   |\n",
        "| eval_loss_q2 | 0.24     |\n",
        "| eval_loss_q3 | 0.686    |\n",
        "| eval_mse     | 0.211    |\n",
        "| eval_mse_q0  | 0.0157   |\n",
        "| eval_mse_q1  | 0.0532   |\n",
        "| eval_mse_q2  | 0.231    |\n",
        "| eval_mse_q3  | 0.677    |\n",
        "---------------------------\n",
        "------------------------\n",
        "| grad_norm | 0.233    |\\n| loss      | 0.239    |\\n| loss_q0   | 0.0258   |\\n| loss_q1   | 0.0555   |\\n| loss_q2   | 0.214    |\\n| loss_q3   | 0.652    |\\n| mse       | 0.231    |\\n| mse_q0    | 0.0171   |\\n| mse_q1    | 0.0468   |\\n| mse_q2    | 0.206    |\\n| mse_q3    | 0.643    |\\n| samples   | 1.27e+07 |\\n| step      | 1.98e+05 |\\n------------------------\n",
        "eval on validation set\n",
        "---------------------------\n",
        "| eval_loss    | 0.241    |\n",
        "| eval_loss_q0 | 0.025    |\n",
        "| eval_loss_q1 | 0.085    |\n",
        "| eval_loss_q2 | 0.238    |\n",
        "| eval_loss_q3 | 0.61     |\n",
        "| eval_mse     | 0.232    |\n",
        "| eval_mse_q0  | 0.0161   |\n",
        "| eval_mse_q1  | 0.0757   |\n",
        "| eval_mse_q2  | 0.23     |\n",
        "| eval_mse_q3  | 0.602    |\n",
        "---------------------------\n",
        "------------------------\n",
        "| grad_norm | 0.231    |\\n| loss      | 0.244    |\\n| loss_q0   | 0.0259   |\\n| loss_q1   | 0.0565   |\\n| loss_q2   | 0.234    |\\n| loss_q3   | 0.647    |\\n| mse       | 0.235    |\\n| mse_q0    | 0.0172   |\\n| mse_q1    | 0.0477   |\\n| mse_q2    | 0.225    |\\n| mse_q3    | 0.638    |\\n| samples   | 1.28e+07 |\\n| step      | 2e+05    |\\n------------------------\n",
        "eval on validation set\n",
        "---------------------------\n",
        "| eval_loss    | 0.214    |\n",
        "| eval_loss_q0 | 0.03     |\n",
        "| eval_loss_q1 | 0.055    |\n",
        "| eval_loss_q2 | 0.239    |\n",
        "| eval_loss_q3 | 0.616    |\n",
        "| eval_mse     | 0.205    |\n",
        "| eval_mse_q0  | 0.0209   |\n",
        "| eval_mse_q1  | 0.0461   |\n",
        "| eval_mse_q2  | 0.23     |\n",
        "| eval_mse_q3  | 0.607    |\n",
        "---------------------------\n",
        "\"\"\"\n",
        "\n",
        "eval_losses = []\n",
        "eval_mses = []\n",
        "steps = []\n",
        "\n",
        "# Regex to find 'eval on validation set' blocks and extract metrics\n",
        "eval_block_pattern = r\"eval on validation set\\s*-+\\s*\\|\\s*eval_loss\\s*\\|\\s*([\\d\\.]+)\\s*\\|\\s*eval_loss_q0\\s*\\|\\s*([\\d\\.]+)\\s*\\|\\s*eval_loss_q1\\s*\\|\\s*([\\d\\.]+)\\s*\\|\\s*eval_loss_q2\\s*\\|\\s*([\\d\\.]+)\\s*\\|\\s*eval_loss_q3\\s*\\|\\s*([\\d\\.]+)\\s*\\|\\s*eval_mse\\s*\\|\\s*([\\d\\.]+)\\s*\\|\\s*eval_mse_q0\\s*\\|\\s*([\\d\\.]+)\\s*\\|\\s*eval_mse_q1\\s*\\|\\s*([\\d\\.]+)\\s*\\|\\s*eval_mse_q2\\s*\\|\\s*([\\d\\.]+)\\s*\\|\\s*eval_mse_q3\\s*\\|\\s*([\\d\\.]+)\\s*\\|\"\n",
        "step_pattern = r\"\\|\\s*step\\s*\\|\\s*([\\d\\.e\\+]+)\\s*\\|\"\n",
        "\n",
        "# Find all evaluation blocks\n",
        "eval_blocks = re.findall(eval_block_pattern, log_content)\n",
        "# Find all step numbers (assuming a step is reported right before an eval)\n",
        "all_steps_in_log = [float(s) for s in re.findall(step_pattern, log_content)]\n",
        "\n",
        "# Due to potential truncation, we try to align steps with eval blocks best effort\n",
        "# Take the last 'n' steps found, where 'n' is the number of eval blocks\n",
        "relevant_steps = all_steps_in_log[-len(eval_blocks):]\n",
        "\n",
        "for i, block_data in enumerate(eval_blocks):\n",
        "    if i < len(relevant_steps): # Ensure we have a corresponding step\n",
        "        steps.append(relevant_steps[i])\n",
        "        eval_losses.append(float(block_data[0]))\n",
        "        eval_mses.append(float(block_data[5]))\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(steps, eval_losses, marker='o', linestyle='-', color='blue')\n",
        "plt.title('Baseline Validation Loss over Steps')\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Evaluation Loss')\n",
        "plt.grid(True)\n",
        "plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0)) # Scientific notation for x-axis\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(steps, eval_mses, marker='o', linestyle='-', color='red')\n",
        "plt.title('Baseline Validation MSE over Steps')\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Evaluation MSE')\n",
        "plt.grid(True)\n",
        "plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0)) # Scientific notation for x-axis\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display baseline output values\n",
        "display(Markdown(\"### Baseline Evaluation Metrics (from the final evaluation logged):\"))\n",
        "display(Markdown(f\"\"\"\n",
        "| Metric       | Value    |\n",
        "| :----------- | :------- |\n",
        "| `eval_loss`    | {eval_losses[-1] if eval_losses else 'N/A'}    |\n",
        "| `eval_loss_q0` | {float(eval_blocks[-1][1]) if eval_blocks else 'N/A'} |\n",
        "| `eval_loss_q1` | {float(eval_blocks[-1][2]) if eval_blocks else 'N/A'} |\n",
        "| `eval_loss_q2` | {float(eval_blocks[-1][3]) if eval_blocks else 'N/A'} |\n",
        "| `eval_loss_q3` | {float(eval_blocks[-1][4]) if eval_blocks else 'N/A'} |\n",
        "| `eval_mse`     | {eval_mses[-1] if eval_mses else 'N/A'}    |\n",
        "| `eval_mse_q0`  | {float(eval_blocks[-1][6]) if eval_blocks else 'N/A'} |\n",
        "| `eval_mse_q1`  | {float(eval_blocks[-1][7]) if eval_blocks else 'N/A'} |\n",
        "| `eval_mse_q2`  | {float(eval_blocks[-1][8]) if eval_blocks else 'N/A'} |\n",
        "| `eval_mse_q3`  | {float(eval_blocks[-1][9]) if eval_blocks else 'N/A'} |\n",
        "\"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993
        },
        "id": "cYzsY_FyoJcD",
        "outputId": "081f9405-647a-43fc-9303-c788a0a71953"
      },
      "id": "cYzsY_FyoJcD",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Baseline Evaluation Metrics (from the final evaluation logged):"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n| Metric       | Value    |\n| :----------- | :------- |\n| `eval_loss`    | N/A    |\n| `eval_loss_q0` | N/A |\n| `eval_loss_q1` | N/A |\n| `eval_loss_q2` | N/A |\n| `eval_loss_q3` | N/A |\n| `eval_mse`     | N/A    |\n| `eval_mse_q0`  | N/A |\n| `eval_mse_q1`  | N/A |\n| `eval_mse_q2`  | N/A |\n| `eval_mse_q3`  | N/A |\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data extracted from the provided DiffusionLM_E2E_Colab_Notebook.ipynb output\n",
        "# Note: The steps are approximate as extracted from the truncated log\n",
        "steps = [184000, 186000, 188000, 190000, 192000, 194000, 196000, 198000, 200000]\n",
        "eval_loss_values = [0.22, 0.233, 0.232, 0.27, 0.286, 0.214, 0.26, 0.241, 0.241]\n",
        "eval_mse_values = [0.211, 0.224, 0.223, 0.261, 0.277, 0.205, 0.252, 0.232, 0.232]\n",
        "\n",
        "# Create the plots\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot for Evaluation Loss\n",
        "plt.subplot(1, 2, 1) # 1 row, 2 columns, 1st plot\n",
        "plt.plot(steps, eval_loss_values, marker='o', linestyle='-', color='b')\n",
        "plt.title('Baseline Model: Evaluation Loss over Training Steps')\n",
        "plt.xlabel('Training Step')\n",
        "plt.ylabel('Evaluation Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot for Evaluation MSE\n",
        "plt.subplot(1, 2, 2) # 1 row, 2 columns, 2nd plot\n",
        "plt.plot(steps, eval_mse_values, marker='o', linestyle='-', color='r')\n",
        "plt.title('Baseline Model: Evaluation MSE over Training Steps')\n",
        "plt.xlabel('Training Step')\n",
        "plt.ylabel('Evaluation MSE')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFinal Baseline Evaluation Metrics:\")\n",
        "print(f\"Eval Loss: {eval_loss_values[-1]}\")\n",
        "print(f\"Eval MSE: {eval_mse_values[-1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "d96RMSAEH-9L",
        "outputId": "a2487a11-736a-4823-b494-97ff220ff674"
      },
      "id": "d96RMSAEH-9L",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Baseline Evaluation Metrics:\n",
            "Eval Loss: 0.241\n",
            "Eval MSE: 0.232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python scripts/batch_decode.py diffusion_models/diff_e2e-tgt_block_rand16_transformer_lr0.0001_0.0_2000_sqrt_Lsimple_h128_s2_d0.1_sd102_xstart_e2e/model050000.pt -1.0 ema\n",
        "\n",
        "!python scripts/batch_decode.py \\\n",
        "  diffusion_models/diff_e2e-tgt_block_rand16_transformer_lr0.0001_0.0_2000_sqrt_Lsimple_h128_s2_d0.1_sd102_xstart_e2e/model050000.pt \\\n",
        "  -1.0 ema \\\n",
        "  > decode_log.txt 2>&1\n"
      ],
      "metadata": {
        "id": "fmWVaKc5lv0M"
      },
      "id": "fmWVaKc5lv0M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 50 decode_log.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ3egLHzsfKb",
        "outputId": "38700dc2-dad6-4dfc-c241-137cee02621e"
      },
      "id": "zZ3egLHzsfKb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top_p = -1.0\n",
            "pattern_ = ema ema\n",
            "diffusion_models/diff_e2e-tgt_block_rand16_transformer_lr0.0001_0.0_2000_sqrt_Lsimple_h128_s2_d0.1_sd102_xstart_e2e/model050000.pt\n",
            "output lists:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b97b10e",
      "metadata": {
        "id": "6b97b10e"
      },
      "source": [
        "## 🛠️ Step 5: Modify noise schedule to cosine\n",
        "\n",
        "You can modify the noise schedule inside the `schedulers/diffusion_schedule.py` file. Replace the `linear_beta_schedule` with a `cosine_beta_schedule`:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "def cosine_beta_schedule(timesteps, s=0.008):\n",
        "    steps = timesteps + 1\n",
        "    x = np.linspace(0, timesteps, steps)\n",
        "    alphas_cumprod = np.cos(((x / timesteps) + s) / (1 + s) * np.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return np.clip(betas, 0.0001, 0.9999)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fe6a297",
      "metadata": {
        "id": "5fe6a297"
      },
      "source": [
        "## 🧪 Step 6: Training & Inference\n",
        "Follow instructions in the Diffusion-LM `README.md` to launch training."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}