{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveensrikar/DiffusionLM/blob/main/DiffusionLM_E2E_Colab_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "759f9789",
      "metadata": {
        "id": "759f9789"
      },
      "source": [
        "# 🚀 Diffusion-LM on E2E NLG Dataset with Cosine Noise Schedule (Google Colab)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zx7x4WZ_3ta",
        "outputId": "370a20d2-83b9-4aef-f8c2-36f0fc7a1409"
      },
      "id": "_Zx7x4WZ_3ta",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📦 Step 1: Set Project Location\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "op3hzL6T9Cdh"
      },
      "id": "op3hzL6T9Cdh"
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR= \"/content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/DiffusionLM\"\n",
        "%cd {BASE_DIR}"
      ],
      "metadata": {
        "id": "v0pHEB6IFpkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df29f73d-a8d0-466c-b9eb-bb24dc0c419c"
      },
      "id": "v0pHEB6IFpkv",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/DiffusionLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cea9af77",
      "metadata": {
        "id": "cea9af77"
      },
      "source": [
        "### 📦 Step 1.1: (if Needed) Clone Diffusion-LM repository, install dependencies, Download the E2E dataset and Preprocess the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "841e71b9",
      "metadata": {
        "id": "841e71b9"
      },
      "outputs": [],
      "source": [
        "# # Clone the repo\n",
        "# !git clone https://github.com/XiangLi1999/Diffusion-LM.git\n",
        "# %cd Diffusion-LM\n",
        "\n",
        "# # Add repo to Python path (instead of pip install)\n",
        "# import sys\n",
        "# sys.path.append('/content/Diffusion-LM')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6cf833e",
      "metadata": {
        "id": "b6cf833e"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p data/e2e_data\n",
        "# !wget https://github.com/tuetschek/e2e-dataset/blob/master/trainset.csv -O data/e2e_data/trainset.csv\n",
        "# !wget https://github.com/tuetschek/e2e-dataset/blob/master/devset.csv -O data/e2e_data/devset.csv\n",
        "# !wget https://github.com/tuetschek/e2e-dataset/blob/master/testset.csv -O data/e2e_data/testset.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✅ Step 1.2: Install Package on session"
      ],
      "metadata": {
        "id": "GoktL92GRuIw"
      },
      "id": "GoktL92GRuIw"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c918fedc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c918fedc",
        "outputId": "a140bcd3-f027-4bce-bd2c-b0e69f2a8093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.3/466.3 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.1/464.1 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m124.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m129.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.2/881.2 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for benepar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pytorch)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install benepar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVQttMyj31Mx",
        "outputId": "4f55af2d-101e-4f28-bf64-146a7ea6531e"
      },
      "id": "xVQttMyj31Mx",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting benepar\n",
            "  Using cached benepar-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: nltk>=3.2 in /usr/local/lib/python3.11/dist-packages (from benepar) (3.9.1)\n",
            "Requirement already satisfied: spacy>=2.0.9 in /usr/local/lib/python3.11/dist-packages (from benepar) (3.8.7)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from benepar) (2.6.0+cu124)\n",
            "Collecting torch-struct>=0.5 (from benepar)\n",
            "  Using cached torch_struct-0.5-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: tokenizers>=0.9.4 in /usr/local/lib/python3.11/dist-packages (from benepar) (0.21.1)\n",
            "Requirement already satisfied: transformers>=4.2.2 in /usr/local/lib/python3.11/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (4.52.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from benepar) (5.29.5)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from benepar) (0.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2->benepar) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2->benepar) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2->benepar) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2->benepar) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (2.11.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.9->benepar) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.9.4->benepar) (0.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->benepar) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->benepar) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.2.2->transformers[tokenizers,torch]>=4.2.2->benepar) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.2.2->transformers[tokenizers,torch]>=4.2.2->benepar) (0.5.3)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (1.7.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[tokenizers,torch]>=4.2.2->benepar) (5.9.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.9.4->benepar) (1.1.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.0.9->benepar) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.9->benepar) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.9->benepar) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.9->benepar) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=2.0.9->benepar) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=2.0.9->benepar) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy>=2.0.9->benepar) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.0.9->benepar) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (0.1.2)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Using cached torch_struct-0.5-py3-none-any.whl (34 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-struct, benepar\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed benepar-0.2.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-struct-0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mpi4py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZZA560GGyew",
        "outputId": "1bd29e0a-5536-436e-87e9-c827397ebc8f"
      },
      "id": "mZZA560GGyew",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpi4py\n",
            "  Using cached mpi4py-4.0.3-cp311-cp311-linux_x86_64.whl\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-4.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✅ Step 2: Import all required libraries"
      ],
      "metadata": {
        "id": "s5LtzDXY1AU2"
      },
      "id": "s5LtzDXY1AU2"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c06795ec",
      "metadata": {
        "id": "c06795ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124bf003-6351-4931-cf8f-3ea3720bb89c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All packages imported successfully!\n",
            "There are 1 GPU(s) available.\n",
            "Device name: NVIDIA A100-SXM4-40GB\n",
            "Device capability: (8, 0)\n",
            "Device total memory [GB]: 42.474471424\n",
            "Mon Jun  9 19:26:08 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0             49W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import transformers\n",
        "import datasets\n",
        "import spacy\n",
        "import wandb\n",
        "import benepar\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "print(\"✅ All packages imported successfully!\")\n",
        "\n",
        "torch.cuda.is_available()\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "  print('Device name:', torch.cuda.get_device_name(0))\n",
        "  print('Device capability:', torch.cuda.get_device_capability(0))\n",
        "  print('Device total memory [GB]:', torch.cuda.get_device_properties(0).total_memory / 1e9)\n",
        "  !nvidia-smi\n",
        "else:\n",
        "  print('No GPU available, using the CPU instead.')\n",
        "  device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e improved-diffusion/\n",
        "!pip install -e transformers/"
      ],
      "metadata": {
        "id": "Ulvn90e4IcUo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4a52bd9-9263-4970-aa04-4fd063d1b2a0"
      },
      "id": "Ulvn90e4IcUo",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/DiffusionLM/improved-diffusion\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: blobfile in /usr/local/lib/python3.11/dist-packages (from improved-diffusion==0.0.0) (3.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from improved-diffusion==0.0.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from improved-diffusion==0.0.0) (4.67.1)\n",
            "Requirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.11/dist-packages (from blobfile->improved-diffusion==0.0.0) (3.23.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from blobfile->improved-diffusion==0.0.0) (2.4.0)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile->improved-diffusion==0.0.0) (5.4.0)\n",
            "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.11/dist-packages (from blobfile->improved-diffusion==0.0.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->improved-diffusion==0.0.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->improved-diffusion==0.0.0) (3.0.2)\n",
            "Installing collected packages: improved-diffusion\n",
            "  Running setup.py develop for improved-diffusion\n",
            "Successfully installed improved-diffusion-0.0.0\n",
            "Obtaining file:///content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/DiffusionLM/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (2.32.3)\n",
            "Collecting sacremoses (from transformers==4.17.0.dev0)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (0.21.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0.dev0) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0.dev0) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0.dev0) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.17.0.dev0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.17.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.17.0.dev0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.17.0.dev0) (2025.4.26)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses->transformers==4.17.0.dev0) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses->transformers==4.17.0.dev0) (1.5.1)\n",
            "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers\n",
            "  Building editable for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.17.0.dev0-0.editable-py3-none-any.whl size=24509 sha256=dc8824477250897e0a8601e8de241beb78b5e862d7edfda59034ee2133f484c6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0ohrhgjc/wheels/a5/94/d8/5b4b332cfb8b1ddc7be4c15f0839360d49b5d8b397eb1e061f\n",
            "Successfully built transformers\n",
            "Installing collected packages: sacremoses, transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.4\n",
            "    Uninstalling transformers-4.52.4:\n",
            "      Successfully uninstalled transformers-4.52.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.17.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sacremoses-0.1.1 transformers-4.17.0.dev0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "45ab01b4679047059f866f2bfcb311f8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c02831",
      "metadata": {
        "id": "c1c02831"
      },
      "source": [
        "## 📁 Step 4: Preprocess the Dataset\n",
        "```python\n",
        "## use this when imported ftom github\n",
        "# !python improved-diffusion/scripts/preprocess_data.py \\\n",
        "#     --data_dir data/e2e_data \\\n",
        "#     --dataset datasets/e2e_data \\\n",
        "#     --tokenizer gpt2 \\\n",
        "#     --output_dir datasets/processed_e2e\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python improved-diffusion/scripts/preprocess_data.py \\\n",
        "    --data_dir data/e2e_data \\\n",
        "    --dataset datasets/e2e_data \\\n",
        "    --tokenizer gpt2 \\\n",
        "    --output_dir datasets/processed_e2e"
      ],
      "metadata": {
        "id": "qeZuYUkxSzSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863dd4c8-79f1-4561-eaaa-c3fd5954294a"
      },
      "id": "qeZuYUkxSzSa",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98161\n",
            "[\"David noticed he had put on a lot of weight recently. He examined his habits to try and figure out the reason. He realized he'd been eating too much fast food lately. He stopped going to burger places and started a vegetarian diet. After a few weeks, he started to feel much better.\", \"Tom had a very short temper. One day a guest made him very angry. He punched a hole in the wall of his house. Tom's guest became afraid and left quickly. Tom sat on his couch filled with regret about his actions.\"]\n",
            "\n",
            "['The dog jumped up on the bed. I told her to go underneath it like she usually does. She refused to budge from her spot. I tried to make enough room for my legs. I gave up and let her sleep partly on top of me.', 'My family was excited for the fourth of july. We decided to have a Bar BQ. A lot of friends attended the event. We ate burgers. At the end of the night we watched fireworks.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model (Default Noise Schedule)\n",
        "\n",
        "```python\n",
        "# !python improved-diffusion/scripts/train.py \\\n",
        "#     --dataset datasets/e2e_data \\\n",
        "#     --data_dir datasets/processed_e2e \\\n",
        "#     --output_dir datasets/trained_e2e_baseline \\\n",
        "#     --num_train_epochs 5 \\\n",
        "#     --learning_rate 5e-5\n",
        "```\n"
      ],
      "metadata": {
        "id": "VoTcSz-EACCw"
      },
      "id": "VoTcSz-EACCw"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab_Shared/Diffusion-LM/improved-diffusion\n",
        "!python scripts/run_train.py --diff_steps 2000 --model_arch transformer --lr 0.0001 --lr_anneal_steps 200000  --seed 102 --noise_schedule sqrt --in_channel 16 --modality e2e-tgt --submit no --padding_mode block --app \"--predict_xstart True --training_mode e2e --vocab_size 821  --e2e_train ../datasets/e2e_data \" --notes xstart_e2e --bsz 128 > decode_log.txt"
      ],
      "metadata": {
        "id": "SSf5xencNjOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b096538-d835-4c77-e8dd-99867dfbc040"
      },
      "id": "SSf5xencNjOh",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Shared/Diffusion-LM/improved-diffusion\n",
            "2025-06-09 19:26:38.718940: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-09 19:26:38.736925: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749497198.758469   15561 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749497198.765094   15561 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-09 19:26:38.786639: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m api_key not configured (no-tty). call wandb.login(key=[your_api_key])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Colab_Shared/Diffusion-LM/improved-diffusion/scripts/train.py\", line 208, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/Colab_Shared/Diffusion-LM/improved-diffusion/scripts/train.py\", line 50, in main\n",
            "    wandb.init(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 1691, in init\n",
            "    wandb._sentry.reraise(e)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/analytics/sentry.py\", line 156, in reraise\n",
            "    raise exc.with_traceback(sys.exc_info()[2])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 1623, in init\n",
            "    wi.maybe_login(init_settings)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 208, in maybe_login\n",
            "    wandb_login._login(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_login.py\", line 314, in _login\n",
            "    key, key_status = wlogin.prompt_api_key(referrer=referrer)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_login.py\", line 242, in prompt_api_key\n",
            "    raise UsageError(\"api_key not configured (no-tty). call \" + directive)\n",
            "wandb.errors.errors.UsageError: api_key not configured (no-tty). call wandb.login(key=[your_api_key])\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/content/drive/MyDrive/Colab_Shared/Diffusion-LM/improved-diffusion/scripts/train.py\", line 208, in <module>\n",
            "[rank0]:     main()\n",
            "[rank0]:   File \"/content/drive/MyDrive/Colab_Shared/Diffusion-LM/improved-diffusion/scripts/train.py\", line 50, in main\n",
            "[rank0]:     wandb.init(\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 1691, in init\n",
            "[rank0]:     wandb._sentry.reraise(e)\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/wandb/analytics/sentry.py\", line 156, in reraise\n",
            "[rank0]:     raise exc.with_traceback(sys.exc_info()[2])\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 1623, in init\n",
            "[rank0]:     wi.maybe_login(init_settings)\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_init.py\", line 208, in maybe_login\n",
            "[rank0]:     wandb_login._login(\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_login.py\", line 314, in _login\n",
            "[rank0]:     key, key_status = wlogin.prompt_api_key(referrer=referrer)\n",
            "[rank0]:                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_login.py\", line 242, in prompt_api_key\n",
            "[rank0]:     raise UsageError(\"api_key not configured (no-tty). call \" + directive)\n",
            "[rank0]: wandb.errors.errors.UsageError: api_key not configured (no-tty). call wandb.login(key=[your_api_key])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#backup !python improved-diffusion/scripts/run_train.py \\\n",
        "#       --diff_steps 2000 \\\n",
        "#       --model_arch transformer \\\n",
        "#       --lr 0.0001 \\\n",
        "#       --lr_anneal_steps 200000  \\\n",
        "#       --seed 102 \\\n",
        "#       --noise_schedule sqrt \\\n",
        "#       --in_channel 16 \\\n",
        "#       --modality e2e-tgt \\\n",
        "#       --submit no \\\n",
        "#       --padding_mode block \\\n",
        "#       --notes xstart_e2e"
      ],
      "metadata": {
        "id": "Dv5W45neHcj7"
      },
      "id": "Dv5W45neHcj7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p generation_outputs\n",
        "# %cd \"/content/drive/MyDrive/Colab_Shared/Diffusion-LM\""
      ],
      "metadata": {
        "id": "nb55HFt2oDV2"
      },
      "id": "nb55HFt2oDV2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "log_file_path = 'improved-diffusion/diffusion_models/diff_e2e-tgt_block_rand16_transformer_lr0.0001_0.0_2000_sqrt_Lsimple_h128_s2_d0.1_sd102_xstart_e2e/log.txt'\n",
        "\n",
        "steps = []\n",
        "losses = []\n",
        "\n",
        "# Regex to find lines containing step and loss\n",
        "step_loss_pattern = re.compile(r\"\\|\\sstep\\s+\\|\\s(\\d+)\\s+\\|.*\\|\\sloss\\s+\\|\\s([\\d\\.]+)\\s+\\|\", re.DOTALL)\n",
        "\n",
        "with open(log_file_path, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "    # Find all matches for the pattern\n",
        "    matches = step_loss_pattern.findall(content)\n",
        "\n",
        "    for match in matches:\n",
        "        # The first training step log is usually a summary of eval loss,\n",
        "        # we will capture the detailed training steps that follow.\n",
        "        pass # The initial block is structured differently.\n",
        "\n",
        "# A more robust way to capture the loss is to look for the specific table format.\n",
        "log_blocks = content.split('------------------------')\n",
        "for block in log_blocks:\n",
        "    if 'loss' in block and 'step' in block:\n",
        "        try:\n",
        "            step_search = re.search(r\"\\|\\s*step\\s*\\|\\s*([\\d.e+]+)\\s*\\|\", block)\n",
        "            loss_search = re.search(r\"\\|\\s*loss\\s*\\|\\s*([\\d.]+)\\s*\\|\", block)\n",
        "\n",
        "            if step_search and loss_search:\n",
        "                step = int(float(step_search.group(1)))\n",
        "                loss = float(loss_search.group(1))\n",
        "                steps.append(step)\n",
        "                losses.append(loss)\n",
        "        except (ValueError, IndexError) as e:\n",
        "            print(f\"Skipping block due to parsing error: {e}\\n{block}\")\n",
        "\n",
        "\n",
        "# Plotting the graph\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(steps, losses, marker='o', linestyle='-')\n",
        "plt.title('Training Loss vs. Steps for Sqrt Noise Schedule')\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d96RMSAEH-9L"
      },
      "id": "d96RMSAEH-9L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model path pattern as a shell variable\n",
        "MODEL_PATH_PATTERN=\"improved-diffusion/diffusion_models/diff_e2e-tgt_block_rand16_transformer_lr0.0001_0.0_2000_sqrt_Lsimple_h128_s2_d0.1_sd102_xstart_e2e*\"\n",
        "\n",
        "# Run the batch_decode.py script with the corrected pattern\n",
        "!python /content/drive/MyDrive/Colab_Shared/Diffusion-LM/improved-diffusion/scripts/batch_decode.py \"$MODEL_PATH_PATTERN\" 0.95 \"ema_0.9999_050000\""
      ],
      "metadata": {
        "id": "zZ3egLHzsfKb"
      },
      "id": "zZ3egLHzsfKb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benepar.download('benepar_en3')"
      ],
      "metadata": {
        "id": "Ksag9V6_seT-"
      },
      "id": "Ksag9V6_seT-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python improved-diffusion/control_gen/eval_control.py \\\n",
        "--input_text generation_outputs/diff_e2e-tgt_block_rand16_transformer_lr0.0001_0.0_2000_sqrt_Lsimple_h128_s2_d0.1_sd102_xstart_e2e.ema_0.9999_200000.pt.samples_-1.0.json \\\n",
        "--input_format paired \\\n",
        "--mode e2e-tgt-ppl \\\n",
        "--model_name_or_path predictability/diff_models/e2e-tgt_e=20_b=64_m=gpt2_wikitext-103-raw-v1_101_wp_finetune_UNK"
      ],
      "metadata": {
        "id": "PRCpr9b4ospM"
      },
      "id": "PRCpr9b4ospM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6b97b10e",
      "metadata": {
        "id": "6b97b10e"
      },
      "source": [
        "## 🛠️ Step 5: Modify noise schedule to cosine\n",
        "\n",
        "You can modify the noise schedule inside the `schedulers/diffusion_schedule.py` file. Replace the `linear_beta_schedule` with a `cosine_beta_schedule`:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "def cosine_beta_schedule(timesteps, s=0.008):\n",
        "    steps = timesteps + 1\n",
        "    x = np.linspace(0, timesteps, steps)\n",
        "    alphas_cumprod = np.cos(((x / timesteps) + s) / (1 + s) * np.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return np.clip(betas, 0.0001, 0.9999)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fe6a297",
      "metadata": {
        "id": "5fe6a297"
      },
      "source": [
        "## 🧪 Step 6: Training & Inference\n",
        "Follow instructions in the Diffusion-LM `README.md` to launch training."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "collapsed_sections": [
        "cea9af77"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}