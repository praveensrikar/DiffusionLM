{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMVHGfpxnnJ/Hz0PlQCNywc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveensrikar/DiffusionLM/blob/main/CosineLLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "h3gEwqoSk-gk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install right packages for Cosine diffusion LM\n",
        "```scrpyt\n",
        "!pip install -q --upgrade pip\n",
        "!pip install -q huggingface_hub==0.28.1 transformers==4.41.1 wandb\n",
        "!pip install -q spacy==3.8.2 numpy==2.0.0 datasets\n",
        "!pip install mpi4py\n",
        "!pip install pytorch torchvision torchaudio cudatoolkit\n",
        "```"
      ],
      "metadata": {
        "id": "DJu-Qf2Rg9LU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElgJNbrUg8Bb",
        "outputId": "234bdf19-9589-4982-8535-35d36ad89c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q huggingface_hub==0.28.1 transformers==4.41.1 wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkydBandhc5O",
        "outputId": "3de87442-7056-46e1-9cc9-6e7dc09dae49"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [transformers]\n",
            "\u001b[1A\u001b[2K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q spacy==3.8.2 numpy==2.0.0 datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3lRit2Shnsd",
        "outputId": "39ab7ce2-f6b3-4ab0-a184-49fe6010af05"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [spacy]\n",
            "\u001b[1A\u001b[2K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mpi4py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nabMbjkPho-w",
        "outputId": "50459dd8-8b6e-4458-d31b-2476872ed989"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpi4py\n",
            "  Downloading mpi4py-4.0.3.tar.gz (466 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-4.0.3-cp311-cp311-linux_x86_64.whl size=4442049 sha256=9885b3c212418e033c5652696e5a7518cc7a2d75331755457c0034ecd0cecc16\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/56/17/bf6ba37aa971a191a8b9eaa188bf5ec855b8911c1c56fb1f84\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-4.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pytorch torchvision torchaudio cudatoolkit"
      ],
      "metadata": {
        "id": "6BUwr0gqhrRl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Drive"
      ],
      "metadata": {
        "id": "p19W5iZniGq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYXRm5pCiFpK",
        "outputId": "e9c4c8a6-d87a-4af8-9892-febd93877c7e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR= \"/content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM\"\n",
        "%cd {BASE_DIR}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5nwMo1diRF9",
        "outputId": "70d64bf6-9e22-4eaa-f5f3-0096f8b808c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Standard libraries\n",
        "\n",
        "```python\n",
        "import torch datasets spacy wandb torch sys\n",
        "import numpy as np\n",
        "```"
      ],
      "metadata": {
        "id": "rE9DipPQhv9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import datasets\n",
        "import spacy\n",
        "import wandb\n",
        "import torch"
      ],
      "metadata": {
        "id": "ZSAGoRX8iVKe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(f\"GPU  available \\n Device name :'{torch.cuda.get_device_name(0)}'\")\n",
        "else:\n",
        "  print(\"No GPU available. Exiting the execution...\")\n",
        "  sys.exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyhPS4cki8qt",
        "outputId": "a941f312-4766-4d3a-81e9-88c4da33a529"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU  available \n",
            " Device name :'NVIDIA L4'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloning the Base paper Github code\n",
        "\n"
      ],
      "metadata": {
        "id": "7Vzeucrdj0zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the name of the folder to check and potentially delete\n",
        "folder_to_check = \"DiffusionLM\"\n",
        "\n",
        "# Check if the folder exists and is a directory\n",
        "if os.path.exists(folder_to_check) and os.path.isdir(folder_to_check):\n",
        "    print(f\"Folder '{folder_to_check}' found. Deleting...\")\n",
        "    # Delete the folder and its contents\n",
        "    shutil.rmtree(folder_to_check)\n",
        "    print(f\"Folder '{folder_to_check}' deleted.\")\n",
        "else:\n",
        "    print(f\"Folder '{folder_to_check}' not found. Cloning...\")\n",
        "\n",
        "# Clone the Diffusion-LM repository from GitHub\n",
        "!git clone https://github.com/XiangLi1999/Diffusion-LM.git\n",
        "\n",
        "# Define the old and new folder names for renaming\n",
        "old_folder_name = \"Diffusion-LM\"\n",
        "new_folder_name = \"DiffusionLM\"\n",
        "\n",
        "# Attempt to rename the cloned directory\n",
        "try:\n",
        "  os.rename(old_folder_name, new_folder_name)\n",
        "  print(f\"Directory '{old_folder_name}' has been renamed to '{new_folder_name}'.\")\n",
        "except OSError as e:\n",
        "    # Handle potential errors during renaming\n",
        "    print(f\"Error renaming directory: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSQqQtO-i2Eq",
        "outputId": "ecafec54-1898-4f59-f132-2abbf00b74fa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder 'DiffusionLM' found. Deleting...\n",
            "Folder 'DiffusionLM' deleted.\n",
            "Cloning into 'Diffusion-LM'...\n",
            "remote: Enumerating objects: 2173, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 2173 (delta 24), reused 11 (delta 11), pack-reused 2108 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2173/2173), 46.02 MiB | 15.28 MiB/s, done.\n",
            "Resolving deltas: 100% (555/555), done.\n",
            "Updating files: 100% (1904/1904), done.\n",
            "Directory 'Diffusion-LM' has been renamed to 'DiffusionLM'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading E2E database"
      ],
      "metadata": {
        "id": "5CW3WBo_k2D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the current working directory to the renamed folder within the base directory\n",
        "%cd {BASE_DIR}/{new_folder_name}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yU5H5TmtVgN",
        "outputId": "ecc07261-fd4e-4388-f737-770356e41b13"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/data/e2e_data\n",
        "%cd /content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/data/e2e_data\n",
        "\n",
        "print(\"Downloading E2E dataset...\")\n",
        "!wget https://raw.githubusercontent.com/tuetschek/e2e-dataset/master/trainset.csv\n",
        "!wget https://raw.githubusercontent.com/tuetschek/e2e-dataset/master/devset.csv\n",
        "!wget https://raw.githubusercontent.com/tuetschek/e2e-dataset/master/testset.csv\n",
        "print(\"Download complete.\")\n",
        "\n",
        "# Change back to the main project directory\n",
        "%cd /content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhfEPeALjJCt",
        "outputId": "eab237a7-3ff7-4924-b996-2bcd89f4f722"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/data/e2e_data\n",
            "Downloading E2E dataset...\n",
            "--2025-06-21 15:34:54--  https://raw.githubusercontent.com/tuetschek/e2e-dataset/master/trainset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9340189 (8.9M) [text/plain]\n",
            "Saving to: ‘trainset.csv’\n",
            "\n",
            "trainset.csv        100%[===================>]   8.91M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-06-21 15:34:58 (95.4 MB/s) - ‘trainset.csv’ saved [9340189/9340189]\n",
            "\n",
            "--2025-06-21 15:34:58--  https://raw.githubusercontent.com/tuetschek/e2e-dataset/master/devset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1161305 (1.1M) [text/plain]\n",
            "Saving to: ‘devset.csv’\n",
            "\n",
            "devset.csv          100%[===================>]   1.11M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-06-21 15:34:59 (66.8 MB/s) - ‘devset.csv’ saved [1161305/1161305]\n",
            "\n",
            "--2025-06-21 15:34:59--  https://raw.githubusercontent.com/tuetschek/e2e-dataset/master/testset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88415 (86K) [text/plain]\n",
            "Saving to: ‘testset.csv’\n",
            "\n",
            "testset.csv         100%[===================>]  86.34K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2025-06-21 15:34:59 (19.8 MB/s) - ‘testset.csv’ saved [88415/88415]\n",
            "\n",
            "Download complete.\n",
            "/content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing project libraries"
      ],
      "metadata": {
        "id": "MkWQd88UlKEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!pip install -e improved-diffusion/\n",
        "# Uninstall the editable installation of transformers\n",
        "!pip uninstall -y transformers\n",
        "# Install a compatible version of transformers from PyPI\n",
        "!pip install transformers==4.41.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbEpBYDLlVZ-",
        "outputId": "c3fea669-7a3e-417a-f5ea-6ee0729ab067"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM\n",
            "Obtaining file:///content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/improved-diffusion\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: blobfile in /usr/local/lib/python3.11/dist-packages (from improved-diffusion==0.0.0) (3.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from improved-diffusion==0.0.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from improved-diffusion==0.0.0) (4.67.1)\n",
            "Requirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.11/dist-packages (from blobfile->improved-diffusion==0.0.0) (3.23.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from blobfile->improved-diffusion==0.0.0) (2.4.0)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile->improved-diffusion==0.0.0) (5.4.0)\n",
            "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.11/dist-packages (from blobfile->improved-diffusion==0.0.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->improved-diffusion==0.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->improved-diffusion==0.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->improved-diffusion==0.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->improved-diffusion==0.0.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->improved-diffusion==0.0.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->improved-diffusion==0.0.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->improved-diffusion==0.0.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->improved-diffusion==0.0.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->improved-diffusion==0.0.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->improved-diffusion==0.0.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->improved-diffusion==0.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->improved-diffusion==0.0.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->improved-diffusion==0.0.0) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m136.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m132.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m134.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, improved-diffusion\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-curand-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 9/11\u001b[0m [nvidia-cusolver-cu12]\u001b[33m  DEPRECATION: Legacy editable install of improved-diffusion==0.0.0 from file:///content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/improved-diffusion (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
            "\u001b[2K  Running setup.py develop for improved-diffusion\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [improved-diffusion]\n",
            "\u001b[1A\u001b[2KSuccessfully installed improved-diffusion-0.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Obtaining file:///content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (2.32.3)\n",
            "Collecting sacremoses (from transformers==4.17.0.dev0)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.17.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0.dev0) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0.dev0) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.17.0.dev0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.17.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.17.0.dev0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.17.0.dev0) (2025.6.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses->transformers==4.17.0.dev0) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses->transformers==4.17.0.dev0) (1.5.1)\n",
            "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers\n",
            "  Building editable for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.17.0.dev0-0.editable-py3-none-any.whl size=24524 sha256=6daa05b33a707f07fdd08deeecbcddf479ddaf3423d9307153b88e066bf26b11\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jjuu46gv/wheels/6f/8b/69/9e876bd487f2cbfca177ade266c2c42b014ffd041e9250b90d\n",
            "Successfully built transformers\n",
            "Installing collected packages: sacremoses, transformers\n",
            "\u001b[2K  Attempting uninstall: transformers\n",
            "\u001b[2K    Found existing installation: transformers 4.41.1\n",
            "\u001b[2K    Uninstalling transformers-4.41.1:\n",
            "\u001b[2K      Successfully uninstalled transformers-4.41.1\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [transformers]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.17.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sacremoses-0.1.1 transformers-4.17.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the Dataset\n",
        "\n",
        "```python\n",
        "!python /content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/improved-diffusion/scripts/preprocess_data.py \\\n",
        "    --data_dir data/e2e_data \\\n",
        "    --dataset datasets/e2e_data \\\n",
        "    --tokenizer gpt2 \\\n",
        "    --output_dir datasets/processed_e2e\n",
        "```\n",
        "not required. as we are using E2E not ROC\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ukjSNkTMlZuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model\n",
        "Baseline"
      ],
      "metadata": {
        "id": "ansV6511lkbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python scripts/run_train.py \\\n",
        "#     --diff_steps 2000 \\\n",
        "#     --model_arch transformer \\\n",
        "#     --lr 0.0001 \\\n",
        "#     --lr_anneal_steps 400000 \\\n",
        "#     --seed 102 \\\n",
        "#     --noise_schedule linear \\\n",
        "#     --in_channel 16 \\\n",
        "#     --modality e2e \\\n",
        "#     --submit no \\\n",
        "#     --padding_mode block \\\n",
        "#     --app \"--predict_xstart True --training_mode e2e-simple --vocab_size 821 --e2e_train datasets/processed_e2e/train.json\" \\\n",
        "#     --notes \"e2e-baseline-linear\"h"
      ],
      "metadata": {
        "id": "EggF5uQlfS4E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {BASE_DIR}/{new_folder_name}/improved-diffusion\n",
        "!python scripts/run_train.py \\\n",
        "--modality e2e \\\n",
        "--bsz 32 \\\n",
        "--lr 1e-04 \\\n",
        "--diff_steps 2000 \\\n",
        "--noise_schedule cosine \\\n",
        "--in_channel 128 \\\n",
        "--hidden_size 128 \\\n",
        "--num_res_blocks 2 \\\n",
        "--dropout 0.1 \\\n",
        "--seed 101 \\\n",
        "--notes \"e2e_cosine_colab_t10\" \\\n",
        "--submit \"no\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6v05sYh2GlG",
        "outputId": "373662f4-9166-456e-9526-e0499529d74a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/improved-diffusion\n",
            " OPENAI_LOGDIR=diffusion_models/diff_e2e_block_rand128_conv-unet_lr0.0001_0.0_2000_cosine_Lsimple_h128_s2_d0.1_sd101_e2e_cosine_colab_t10  TOKENIZERS_PARALLELISM=false python scripts/train.py   --checkpoint_path diffusion_models/diff_e2e_block_rand128_conv-unet_lr0.0001_0.0_2000_cosine_Lsimple_h128_s2_d0.1_sd101_e2e_cosine_colab_t10 --model_arch conv-unet --modality e2e --save_interval 50000 --lr 0.0001 --batch_size 32  --diffusion_steps 2000 --noise_schedule cosine  --use_kl False --learn_sigma False  --image_size 8 --num_channels 128 --seed 101 --dropout 0.1 --in_channel 128 --out_channel 128 --padding_mode block --experiment random  --lr_anneal_steps 400000 --weight_decay 0.0 --num_res_blocks 2  \n",
            "2025-06-21 15:38:31.832854: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-21 15:38:31.851075: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750520311.872349    8373 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750520311.878831    8373 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-21 15:38:31.900046: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Logging to diffusion_models/diff_e2e_block_rand128_conv-unet_lr0.0001_0.0_2000_cosine_Lsimple_h128_s2_d0.1_sd101_e2e_cosine_colab_t10\n",
            "creating model and diffusion...\n",
            "creating model, based on conv-unet\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/improved-diffusion/scripts/train.py\", line 208, in <module>\n",
            "[rank0]:     main()\n",
            "[rank0]:   File \"/content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/improved-diffusion/scripts/train.py\", line 35, in main\n",
            "[rank0]:     model, diffusion = create_model_and_diffusion(\n",
            "[rank0]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/improved-diffusion/improved_diffusion/script_util.py\", line 77, in create_model_and_diffusion\n",
            "[rank0]:     model = create_model(\n",
            "[rank0]:             ^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/improved-diffusion/improved_diffusion/script_util.py\", line 154, in create_model\n",
            "[rank0]:     return UNetModel(\n",
            "[rank0]:            ^^^^^^^^^^\n",
            "[rank0]: TypeError: UNetModel.__init__() got an unexpected keyword argument 'logits_mode'\n",
            "[rank0]:[W621 15:38:38.138894398 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation\n",
        "```python\n",
        "!python /content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/improved-diffusion/scripts/batch_decode.py \\\n",
        "    --model_path /content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/checkpoints/e2e_cosine_schedule_baseline/ema_0.9999_200000.pt \\\n",
        "    --out_dir /content/drive/MyDrive/Colab_Code/UA_MS_IS_ML_23-25/Capstone/05_Code/CosineDiffusionLLM/DiffusionLM/generated_text/baseline \\\n",
        "    --batch_size 64\n",
        "    ```\n",
        "  "
      ],
      "metadata": {
        "id": "Aovimx8zg0_C"
      }
    }
  ]
}